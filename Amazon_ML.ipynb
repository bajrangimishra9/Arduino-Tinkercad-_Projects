{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9391920,
          "sourceType": "datasetVersion",
          "datasetId": 5699506
        },
        {
          "sourceId": 9407156,
          "sourceType": "datasetVersion",
          "datasetId": 5711691
        },
        {
          "sourceId": 9408839,
          "sourceType": "datasetVersion",
          "datasetId": 5713039
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Amazon-ML",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bajrangimishra9/Arduino-Tinkercad-_Projects/blob/main/Amazon_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'amazon-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5699506%2F9391920%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240916%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240916T065303Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6836ce45a757473268770024a8452bc853aa8e34da5043624cfd8164d42cb2ccb3a9817f2f4a1122bf2bf00b666859400f01ade8f6fe701ff3f04cebe3962021f310b94b2606f8986a0c46dc092e4ca64fe6c95ca4a430ecfb0271bb3a4e962ce217cc3ae92e495d216a7d80a88d01df034a365ec853c07fca7d3da69e74954091a54d945e9a0cc6784b9f61fc5e4ec085ee098b405a84d00824bc5149a6390d3f733251190b895b7a90cc651c5f3e48c977484209896d045047be154d3882a68dcdb85e6328dd928295452e4e2050189cab66a6bf396336b9f451c49092724939dcae3f0ada2110af2947bf79af8ca5058e25662c4e89c1c644d91d235a3d65,test-dataset-file:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5711691%2F9407156%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240916%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240916T065303Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D31d3bd4d38d0c48d19dfbfd8ad1315a79fb96bda8d4f5129b9abfd1e8ed15901b8dc20aeab6d779fd37743ce31edb03eaa36d644a8c164b8dd235f9afae641f927294834902f00ccd66aa0095456af4a647f0b5690d6acd1e0013c40fa7acc3dba0ba0e9109802e185c45b160d4e2408a05cdcf722c2d70a24fb3e9b90322280b15a227af0ab859be1d5f26184ae90713b1a403f97bb7d86ea66624b004803d403359f607473bc0aa45632fbfa3399c13816a16cdc998c80090668d01ee1906fe98cf790a2938a8fa45fdd5eb226a85b24d52c980fb1a62b812fa1d070724d7124b96bb9decf1c424600b05919f0a10c929ff366b813c6178a027a873c783a57,after-training:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5713039%2F9408839%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240916%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240916T065303Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D63aab3eb652e06c0428686b6ccf8e4cee6f5a68c1e1265d2fcc7e31302172b8b2b363193ee34ab3edee5f498e211835aa093c6d74d45e66a6fae643fe916b48f9f805f69cdf78b79dce258af6c08fac0cb242331af26d24caa6fbf82fc1c5206c579c4595ee398a6617b0a90db7c668e7a8e90b80064109e830758c5f3ea0d9e55a6c1131038afd46b384d631c7570bec12083b531a1f557dc236af66899c19d27d467b58097efead684ea48170ee2d0ef2b7ae2e4c4dcb2435b288b29da165e9e45b92670afca376e775f649b1d083749e994d721a6e9d711fbd3a90ac637d2e0cb4178717c1340272e456fa161d701b3788f3076e6d03615397eec5de0f254'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "LfD_l5kvmz1z"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-16T06:49:25.670756Z",
          "iopub.execute_input": "2024-09-16T06:49:25.671034Z",
          "iopub.status.idle": "2024-09-16T06:49:26.061848Z",
          "shell.execute_reply.started": "2024-09-16T06:49:25.671002Z",
          "shell.execute_reply": "2024-09-16T06:49:26.060915Z"
        },
        "trusted": true,
        "id": "vbmtg71mmz13",
        "outputId": "f481c00e-8c0e-4351-e9db-bdbe46ce20ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/test-dataset-file/dataset_part2.csv\n/kaggle/input/after-training/trained_model.pkl\n/kaggle/input/after-training/vectorizer.pkl\n/kaggle/input/after-training/predicted_units.csv\n/kaggle/input/amazon-dataset/dataset/._sample_test_out.csv\n/kaggle/input/amazon-dataset/dataset/._train.csv\n/kaggle/input/amazon-dataset/dataset/._sample_test.csv\n/kaggle/input/amazon-dataset/dataset/._sample_test_out_fail.csv\n/kaggle/input/amazon-dataset/dataset/._test.csv\n/kaggle/input/amazon-dataset/src/._constants.py\n/kaggle/input/amazon-dataset/src/._utils.py\n/kaggle/input/amazon-dataset/src/._sanity.py\n/kaggle/input/amazon-dataset/src/._test.ipynb\n/kaggle/input/amazon-dataset/student_resource 3/._src\n/kaggle/input/amazon-dataset/student_resource 3/._sample_code.py\n/kaggle/input/amazon-dataset/student_resource 3/README.md\n/kaggle/input/amazon-dataset/student_resource 3/._README.md\n/kaggle/input/amazon-dataset/student_resource 3/._dataset\n/kaggle/input/amazon-dataset/student_resource 3/sample_code.py\n/kaggle/input/amazon-dataset/student_resource 3/dataset/sample_test.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/._sample_test_out.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/sample_test_out_fail.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/sample_test_out.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/._train.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/._sample_test.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/._sample_test_out_fail.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/train.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/test.csv\n/kaggle/input/amazon-dataset/student_resource 3/dataset/._test.csv\n/kaggle/input/amazon-dataset/student_resource 3/src/._constants.py\n/kaggle/input/amazon-dataset/student_resource 3/src/sanity.py\n/kaggle/input/amazon-dataset/student_resource 3/src/constants.py\n/kaggle/input/amazon-dataset/student_resource 3/src/._utils.py\n/kaggle/input/amazon-dataset/student_resource 3/src/test.ipynb\n/kaggle/input/amazon-dataset/student_resource 3/src/utils.py\n/kaggle/input/amazon-dataset/student_resource 3/src/._sanity.py\n/kaggle/input/amazon-dataset/student_resource 3/src/._test.ipynb\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/amazon-dataset/student_resource 3/dataset/train.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:49:26.063504Z",
          "iopub.execute_input": "2024-09-16T06:49:26.063943Z",
          "iopub.status.idle": "2024-09-16T06:49:26.675194Z",
          "shell.execute_reply.started": "2024-09-16T06:49:26.063906Z",
          "shell.execute_reply": "2024-09-16T06:49:26.674392Z"
        },
        "trusted": true,
        "id": "bHS-8e_Hmz15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:49:26.676291Z",
          "iopub.execute_input": "2024-09-16T06:49:26.676624Z",
          "iopub.status.idle": "2024-09-16T06:49:26.698097Z",
          "shell.execute_reply.started": "2024-09-16T06:49:26.67659Z",
          "shell.execute_reply": "2024-09-16T06:49:26.697175Z"
        },
        "trusted": true,
        "id": "M9EFV2o1mz15",
        "outputId": "1f56dda5-db96-4969-f8f5-9c7a41a2138b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                          image_link  group_id  entity_name  \\\n0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n\n     entity_value  \n0      500.0 gram  \n1         1.0 cup  \n2      0.709 gram  \n3      0.709 gram  \n4  1400 milligram  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_link</th>\n      <th>group_id</th>\n      <th>entity_name</th>\n      <th>entity_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n      <td>748919</td>\n      <td>item_weight</td>\n      <td>500.0 gram</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n      <td>916768</td>\n      <td>item_volume</td>\n      <td>1.0 cup</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n      <td>459516</td>\n      <td>item_weight</td>\n      <td>0.709 gram</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n      <td>459516</td>\n      <td>item_weight</td>\n      <td>0.709 gram</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n      <td>731432</td>\n      <td>item_weight</td>\n      <td>1400 milligram</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:49:26.700024Z",
          "iopub.execute_input": "2024-09-16T06:49:26.70035Z",
          "iopub.status.idle": "2024-09-16T06:49:40.965871Z",
          "shell.execute_reply.started": "2024-09-16T06:49:26.700316Z",
          "shell.execute_reply": "2024-09-16T06:49:40.96478Z"
        },
        "trusted": true,
        "id": "uHEst9Bmmz16",
        "outputId": "249b5ebe-702b-4c1f-b68d-91da4897e6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: easyocr in /opt/conda/lib/python3.10/site-packages (1.7.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from easyocr) (2.4.0)\nRequirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.19.0)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from easyocr) (4.10.0.84)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from easyocr) (9.5.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.23.2)\nRequirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.6.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from easyocr) (6.0.2)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.8.5.post1)\nRequirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.3.0.post5)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.11.1.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (3.3)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (0.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (1.13.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->easyocr) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->easyocr) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->easyocr) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For single image extraction"
      ],
      "metadata": {
        "id": "_w8URLSSmz16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) To see detailed extraction"
      ],
      "metadata": {
        "id": "hht1xL9mmz18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import easyocr\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import re\n",
        "\n",
        "# Initialize the EasyOCR reader (CPU mode if GPU is not available or has low memory)\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Define regex patterns based on the allowed units\n",
        "patterns = {\n",
        "    'gram': r'(\\d+(\\.\\d+)?)\\s*(g|grams?)',\n",
        "    'kilogram': r'(\\d+(\\.\\d+)?)\\s*(kg|kilograms?)',\n",
        "    'milligram': r'(\\d+(\\.\\d+)?)\\s*(mg|milligrams?)',\n",
        "    'microgram': r'(\\d+(\\.\\d+)?)\\s*(µg|micrograms?)',\n",
        "    'ounce': r'(\\d+(\\.\\d+)?)\\s*(oz|ounces?)',\n",
        "    'pound': r'(\\d+(\\.\\d+)?)\\s*(lb|pounds?)',\n",
        "    'ton': r'(\\d+(\\.\\d+)?)\\s*(ton|tons?)',\n",
        "    'centimetre': r'(\\d+(\\.\\d+)?)\\s*(cm|centimetre|centimeters?)',\n",
        "    'foot': r'(\\d+(\\.\\d+)?)\\s*(ft|foot|feet)',\n",
        "    'inch': r'(\\d+(\\.\\d+)?)\\s*(in|inch|inches)',\n",
        "    'metre': r'(\\d+(\\.\\d+)?)\\s*(m|metre|meters?)',\n",
        "    'millimetre': r'(\\d+(\\.\\d+)?)\\s*(mm|millimetre|millimeters?)',\n",
        "    'yard': r'(\\d+(\\.\\d+)?)\\s*(yd|yards?)',\n",
        "    'kilovolt': r'(\\d+(\\.\\d+)?)\\s*(kv|kilovolts?)',\n",
        "    'millivolt': r'(\\d+(\\.\\d+)?)\\s*(mv|millivolts?)',\n",
        "    'volt': r'(\\d+(\\.\\d+)?)\\s*(v|volts?)',\n",
        "    'kilowatt': r'(\\d+(\\.\\d+)?)\\s*(kw|kilowatts?)',\n",
        "    'watt': r'(\\d+(\\.\\d+)?)\\s*(w|watts?)',\n",
        "    'centilitre': r'(\\d+(\\.\\d+)?)\\s*(cl|centilitres?)',\n",
        "    'cubic foot': r'(\\d+(\\.\\d+)?)\\s*(cubic foot|cubic feet)',\n",
        "    'cubic inch': r'(\\d+(\\.\\d+)?)\\s*(cubic inch|cubic inches)',\n",
        "    'cup': r'(\\d+(\\.\\d+)?)\\s*(cup|cups?)',\n",
        "    'decilitre': r'(\\d+(\\.\\d+)?)\\s*(dl|decilitres?)',\n",
        "    'fluid ounce': r'(\\d+(\\.\\d+)?)\\s*(fl oz|fluid ounces?)',\n",
        "    'gallon': r'(\\d+(\\.\\d+)?)\\s*(gallon|gallons?)',\n",
        "    'imperial gallon': r'(\\d+(\\.\\d+)?)\\s*(imperial gallon|imperial gallons?)',\n",
        "    'litre': r'(\\d+(\\.\\d+)?)\\s*(l|litre|liters?)',\n",
        "    'microlitre': r'(\\d+(\\.\\d+)?)\\s*(µl|microlitre|microlitres?)',\n",
        "    'millilitre': r'(\\d+(\\.\\d+)?)\\s*(ml|millilitre|millilitres?)',\n",
        "    'pint': r'(\\d+(\\.\\d+)?)\\s*(pt|pints?)',\n",
        "    'quart': r'(\\d+(\\.\\d+)?)\\s*(qt|quarts?)',\n",
        "}\n",
        "\n",
        "# Map entity names to their corresponding unit patterns\n",
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "}\n",
        "\n",
        "# Allowed units set based on entity_unit_map\n",
        "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
        "\n",
        "# Function to download an image from a URL\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    return img\n",
        "\n",
        "# Preprocessing function to clean up OCR text\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "\n",
        "    # Replace \"O\" with \"0\" (to handle common OCR errors like \"140OmG\")\n",
        "    text = text.replace(\"o\", \"0\")\n",
        "\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Remove any unnecessary punctuation that might interfere with matching\n",
        "    text = re.sub(r'[^\\w\\s.,]', '', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Function to extract various units from the text\n",
        "def extract_units(text, entity_name):\n",
        "    extracted_units = set()\n",
        "\n",
        "    # Preprocess the text before extracting units\n",
        "    cleaned_text = preprocess_text(text)\n",
        "\n",
        "    if entity_name in entity_unit_map:\n",
        "        unit_list = entity_unit_map[entity_name]\n",
        "        for unit in unit_list:\n",
        "            if unit in patterns:\n",
        "                pattern = patterns[unit]\n",
        "                matches = re.findall(pattern, cleaned_text)\n",
        "                if matches:\n",
        "                    # Format as \"value unit\" and store unique entries\n",
        "                    for match in matches:\n",
        "                        value = float(match[0])\n",
        "                        formatted_entry = f\"{value} {unit}\"\n",
        "                        extracted_units.add(formatted_entry)\n",
        "\n",
        "    return extracted_units\n",
        "\n",
        "# Function to rotate the image and check OCR text\n",
        "def rotate_and_extract(image):\n",
        "    # Initialize variables to track the best result\n",
        "    best_text = \"\"\n",
        "    best_angle = 0\n",
        "\n",
        "    # Try OCR on the original and rotated images\n",
        "    for angle in [0, 90, 180, 270]:\n",
        "        rotated_img = image.rotate(angle, expand=True)\n",
        "\n",
        "        # Convert the rotated image to a numpy array for easyocr\n",
        "        rotated_img_np = np.array(rotated_img)\n",
        "\n",
        "        # Extract text from rotated image\n",
        "        img_text = reader.readtext(rotated_img_np)\n",
        "        final_text = \" \".join([text for _, text, __ in img_text])\n",
        "\n",
        "        if len(final_text.strip()) > len(best_text.strip()):  # Choose the best text based on length\n",
        "            best_text = final_text\n",
        "            best_angle = angle\n",
        "\n",
        "    # Return the best text and angle\n",
        "    return best_text, best_angle\n",
        "\n",
        "# Function to process each image URL\n",
        "def process_image_url(image_url, entity_name):\n",
        "    # Download and process the image\n",
        "    image = download_image(image_url)\n",
        "    final_text, best_angle = rotate_and_extract(image)\n",
        "\n",
        "    # Extract units from the final text based on the entity_name\n",
        "    units = extract_units(final_text, entity_name)\n",
        "\n",
        "    return final_text, best_angle, units\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file_path = '/kaggle/input/amazon-dataset/student_resource 3/dataset/train.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Limit to first 30 links for processing\n",
        "df = df.head(30)\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Iterate through each image URL in the CSV file\n",
        "for index, row in df.iterrows():\n",
        "    image_url = row['image_link']  # Assuming the CSV column is named 'image_link'\n",
        "    entity_name = row['entity_name']  # Assuming this column specifies what entity to extract (e.g., weight, volume)\n",
        "\n",
        "    print(f\"Processing image from URL: {image_url} for entity: {entity_name}\")\n",
        "\n",
        "    final_text, best_angle, units = process_image_url(image_url, entity_name)\n",
        "\n",
        "    # Prepare the result row\n",
        "    result_row = {\n",
        "        'image_link': image_url,\n",
        "        'entity_name': entity_name,\n",
        "        'extracted_text': final_text,\n",
        "        'best_angle': best_angle,\n",
        "        'predicted': list(units)  # Convert set to list for the predicted result\n",
        "    }\n",
        "\n",
        "    # Append the result to the list\n",
        "    results.append(result_row)\n",
        "\n",
        "    # Print results for each image\n",
        "    print(f\"Extracted Text (Best angle {best_angle} degrees): {final_text}\")\n",
        "    print(f\"Extracted Units for {entity_name}: {result_row['predicted']}\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "# Create a new DataFrame from results and save it as a CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('predicted_units.csv', index=False)\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-15T17:04:13.923526Z",
          "iopub.execute_input": "2024-09-15T17:04:13.923967Z",
          "iopub.status.idle": "2024-09-15T17:04:13.940174Z",
          "shell.execute_reply.started": "2024-09-15T17:04:13.923918Z",
          "shell.execute_reply": "2024-09-15T17:04:13.939266Z"
        },
        "trusted": true,
        "id": "J7Lk5XoNmz18",
        "outputId": "82d78e4b-b82a-4e20-fefb-39d0e3a2f24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'import easyocr\\nimport pandas as pd\\nfrom PIL import Image\\nimport numpy as np\\nimport requests\\nfrom io import BytesIO\\nimport re\\n\\n# Initialize the EasyOCR reader (CPU mode if GPU is not available or has low memory)\\nreader = easyocr.Reader([\\'en\\'], gpu=True)\\n\\n# Define regex patterns based on the allowed units\\npatterns = {\\n    \\'gram\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(g|grams?)\\',\\n    \\'kilogram\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(kg|kilograms?)\\',\\n    \\'milligram\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(mg|milligrams?)\\',\\n    \\'microgram\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(µg|micrograms?)\\',\\n    \\'ounce\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(oz|ounces?)\\',\\n    \\'pound\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(lb|pounds?)\\',\\n    \\'ton\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(ton|tons?)\\',\\n    \\'centimetre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(cm|centimetre|centimeters?)\\',\\n    \\'foot\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(ft|foot|feet)\\',\\n    \\'inch\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(in|inch|inches)\\',\\n    \\'metre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(m|metre|meters?)\\',\\n    \\'millimetre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(mm|millimetre|millimeters?)\\',\\n    \\'yard\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(yd|yards?)\\',\\n    \\'kilovolt\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(kv|kilovolts?)\\',\\n    \\'millivolt\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(mv|millivolts?)\\',\\n    \\'volt\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(v|volts?)\\',\\n    \\'kilowatt\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(kw|kilowatts?)\\',\\n    \\'watt\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(w|watts?)\\',\\n    \\'centilitre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(cl|centilitres?)\\',\\n    \\'cubic foot\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(cubic foot|cubic feet)\\',\\n    \\'cubic inch\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(cubic inch|cubic inches)\\',\\n    \\'cup\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(cup|cups?)\\',\\n    \\'decilitre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(dl|decilitres?)\\',\\n    \\'fluid ounce\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(fl oz|fluid ounces?)\\',\\n    \\'gallon\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(gallon|gallons?)\\',\\n    \\'imperial gallon\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(imperial gallon|imperial gallons?)\\',\\n    \\'litre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(l|litre|liters?)\\',\\n    \\'microlitre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(µl|microlitre|microlitres?)\\',\\n    \\'millilitre\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(ml|millilitre|millilitres?)\\',\\n    \\'pint\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(pt|pints?)\\',\\n    \\'quart\\': r\\'(\\\\d+(\\\\.\\\\d+)?)\\\\s*(qt|quarts?)\\',\\n}\\n\\n# Map entity names to their corresponding unit patterns\\nentity_unit_map = {\\n    \\'width\\': {\\'centimetre\\', \\'foot\\', \\'inch\\', \\'metre\\', \\'millimetre\\', \\'yard\\'},\\n    \\'depth\\': {\\'centimetre\\', \\'foot\\', \\'inch\\', \\'metre\\', \\'millimetre\\', \\'yard\\'},\\n    \\'height\\': {\\'centimetre\\', \\'foot\\', \\'inch\\', \\'metre\\', \\'millimetre\\', \\'yard\\'},\\n    \\'item_weight\\': {\\'gram\\', \\'kilogram\\', \\'microgram\\', \\'milligram\\', \\'ounce\\', \\'pound\\', \\'ton\\'},\\n    \\'maximum_weight_recommendation\\': {\\'gram\\', \\'kilogram\\', \\'microgram\\', \\'milligram\\', \\'ounce\\', \\'pound\\', \\'ton\\'},\\n    \\'voltage\\': {\\'kilovolt\\', \\'millivolt\\', \\'volt\\'},\\n    \\'wattage\\': {\\'kilowatt\\', \\'watt\\'},\\n    \\'item_volume\\': {\\'centilitre\\', \\'cubic foot\\', \\'cubic inch\\', \\'cup\\', \\'decilitre\\', \\'fluid ounce\\', \\'gallon\\', \\'imperial gallon\\', \\'litre\\', \\'microlitre\\', \\'millilitre\\', \\'pint\\', \\'quart\\'}\\n}\\n\\n# Allowed units set based on entity_unit_map\\nallowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\\n\\n# Function to download an image from a URL\\ndef download_image(url):\\n    response = requests.get(url)\\n    img = Image.open(BytesIO(response.content))\\n    return img\\n\\n# Preprocessing function to clean up OCR text\\ndef preprocess_text(text):\\n    # Lowercase the text\\n    text = text.lower()\\n    \\n    # Replace \"O\" with \"0\" (to handle common OCR errors like \"140OmG\")\\n    text = text.replace(\"o\", \"0\")\\n    \\n    # Replace multiple spaces with a single space\\n    text = re.sub(r\\'\\\\s+\\', \\' \\', text)\\n    \\n    # Remove any unnecessary punctuation that might interfere with matching\\n    text = re.sub(r\\'[^\\\\w\\\\s.,]\\', \\'\\', text)\\n    \\n    return text\\n\\n# Function to extract various units from the text\\ndef extract_units(text, entity_name):\\n    extracted_units = set()\\n\\n    # Preprocess the text before extracting units\\n    cleaned_text = preprocess_text(text)\\n\\n    if entity_name in entity_unit_map:\\n        unit_list = entity_unit_map[entity_name]\\n        for unit in unit_list:\\n            if unit in patterns:\\n                pattern = patterns[unit]\\n                matches = re.findall(pattern, cleaned_text)\\n                if matches:\\n                    # Format as \"value unit\" and store unique entries\\n                    for match in matches:\\n                        value = float(match[0])\\n                        formatted_entry = f\"{value} {unit}\"\\n                        extracted_units.add(formatted_entry)\\n\\n    return extracted_units\\n\\n# Function to rotate the image and check OCR text\\ndef rotate_and_extract(image):\\n    # Initialize variables to track the best result\\n    best_text = \"\"\\n    best_angle = 0\\n    \\n    # Try OCR on the original and rotated images\\n    for angle in [0, 90, 180, 270]:\\n        rotated_img = image.rotate(angle, expand=True)\\n        \\n        # Convert the rotated image to a numpy array for easyocr\\n        rotated_img_np = np.array(rotated_img)\\n        \\n        # Extract text from rotated image\\n        img_text = reader.readtext(rotated_img_np)\\n        final_text = \" \".join([text for _, text, __ in img_text])\\n        \\n        if len(final_text.strip()) > len(best_text.strip()):  # Choose the best text based on length\\n            best_text = final_text\\n            best_angle = angle\\n    \\n    # Return the best text and angle\\n    return best_text, best_angle\\n\\n# Function to process each image URL\\ndef process_image_url(image_url, entity_name):\\n    # Download and process the image\\n    image = download_image(image_url)\\n    final_text, best_angle = rotate_and_extract(image)\\n    \\n    # Extract units from the final text based on the entity_name\\n    units = extract_units(final_text, entity_name)\\n    \\n    return final_text, best_angle, units\\n\\n# Load the CSV file\\ncsv_file_path = \\'/kaggle/input/amazon-dataset/student_resource 3/dataset/train.csv\\'\\ndf = pd.read_csv(csv_file_path)\\n\\n# Limit to first 30 links for processing\\ndf = df.head(30)\\n\\n# Initialize a list to store results\\nresults = []\\n\\n# Iterate through each image URL in the CSV file\\nfor index, row in df.iterrows():\\n    image_url = row[\\'image_link\\']  # Assuming the CSV column is named \\'image_link\\'\\n    entity_name = row[\\'entity_name\\']  # Assuming this column specifies what entity to extract (e.g., weight, volume)\\n    \\n    print(f\"Processing image from URL: {image_url} for entity: {entity_name}\")\\n    \\n    final_text, best_angle, units = process_image_url(image_url, entity_name)\\n    \\n    # Prepare the result row\\n    result_row = {\\n        \\'image_link\\': image_url,\\n        \\'entity_name\\': entity_name,\\n        \\'extracted_text\\': final_text,\\n        \\'best_angle\\': best_angle,\\n        \\'predicted\\': list(units)  # Convert set to list for the predicted result\\n    }\\n    \\n    # Append the result to the list\\n    results.append(result_row)\\n    \\n    # Print results for each image\\n    print(f\"Extracted Text (Best angle {best_angle} degrees): {final_text}\")\\n    print(f\"Extracted Units for {entity_name}: {result_row[\\'predicted\\']}\")\\n    print(\"--------------------------------------------------\")\\n\\n# Create a new DataFrame from results and save it as a CSV\\nresults_df = pd.DataFrame(results)\\nresults_df.to_csv(\\'predicted_units.csv\\', index=False)\\n'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Didn't want to see details"
      ],
      "metadata": {
        "id": "mjTZLPUOmz19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import urllib\n",
        "import re\n",
        "import warnings\n",
        "import os\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Regex patterns for units\n",
        "patterns = {\n",
        "    'gram': r'(\\d+(\\.\\d+)?)\\s*(g|grams?)',\n",
        "    'kilogram': r'(\\d+(\\.\\d+)?)\\s*(kg|kilograms?)',\n",
        "    'milligram': r'(\\d+(\\.\\d+)?)\\s*(mg|milligrams?)',\n",
        "    'microgram': r'(\\d+(\\.\\d+)?)\\s*(µg|micrograms?)',\n",
        "    'ounce': r'(\\d+(\\.\\d+)?)\\s*(oz|ounces?)',\n",
        "    'pound': r'(\\d+(\\.\\d+)?)\\s*(lb|pounds?)',\n",
        "    'ton': r'(\\d+(\\.\\d+)?)\\s*(ton|tons?)',\n",
        "    'centimetre': r'(\\d+(\\.\\d+)?)\\s*(cm|centimetre|centimeters?)',\n",
        "    'foot': r'(\\d+(\\.\\d+)?)\\s*(ft|foot|feet)',\n",
        "    'inch': r'(\\d+(\\.\\d+)?)\\s*(in|inch|inches)',\n",
        "    'metre': r'(\\d+(\\.\\d+)?)\\s*(m|metre|meters?)',\n",
        "    'millimetre': r'(\\d+(\\.\\d+)?)\\s*(mm|millimetre|millimeters?)',\n",
        "    'yard': r'(\\d+(\\.\\d+)?)\\s*(yd|yards?)',\n",
        "    'kilovolt': r'(\\d+(\\.\\d+)?)\\s*(kv|kilovolts?)',\n",
        "    'millivolt': r'(\\d+(\\.\\d+)?)\\s*(mv|millivolts?)',\n",
        "    'volt': r'(\\d+(\\.\\d+)?)\\s*(v|volts?)',\n",
        "    'kilowatt': r'(\\d+(\\.\\d+)?)\\s*(kw|kilowatts?)',\n",
        "    'watt': r'(\\d+(\\.\\d+)?)\\s*(w|watts?)',\n",
        "    'centilitre': r'(\\d+(\\.\\d+)?)\\s*(cl|centilitres?)',\n",
        "    'cubic foot': r'(\\d+(\\.\\d+)?)\\s*(cubic foot|cubic feet)',\n",
        "    'cubic inch': r'(\\d+(\\.\\d+)?)\\s*(cubic inch|cubic inches)',\n",
        "    'cup': r'(\\d+(\\.\\d+)?)\\s*(cup|cups?)',\n",
        "    'decilitre': r'(\\d+(\\.\\d+)?)\\s*(dl|decilitres?)',\n",
        "    'fluid ounce': r'(\\d+(\\.\\d+)?)\\s*(fl oz|fluid ounces?)',\n",
        "    'gallon': r'(\\d+(\\.\\d+)?)\\s*(gallon|gallons?)',\n",
        "    'imperial gallon': r'(\\d+(\\.\\d+)?)\\s*(imperial gallon|imperial gallons?)',\n",
        "    'litre': r'(\\d+(\\.\\d+)?)\\s*(l|litre|liters?)',\n",
        "    'microlitre': r'(\\d+(\\.\\d+)?)\\s*(µl|microlitre|microlitres?)',\n",
        "    'millilitre': r'(\\d+(\\.\\d+)?)\\s*(ml|millilitre|millilitres?)',\n",
        "    'pint': r'(\\d+(\\.\\d+)?)\\s*(pt|pints?)',\n",
        "    'quart': r'(\\d+(\\.\\d+)?)\\s*(qt|quarts?)',\n",
        "}\n",
        "\n",
        "# Map entity names to their corresponding unit patterns\n",
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "}\n",
        "\n",
        "# Allowed units\n",
        "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
        "\n",
        "# Download an image from URL with retries and placeholder on failure\n",
        "def download_image(image_link, save_folder, retries=3, delay=3):\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    # Skip if image already exists\n",
        "    if os.path.exists(image_save_path):\n",
        "        return\n",
        "\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(image_link, image_save_path)\n",
        "            return\n",
        "        except Exception:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    # Create a placeholder image in case of failure\n",
        "    Image.new('RGB', (100, 100), color='black').save(image_save_path)\n",
        "\n",
        "# Parallel image downloading function\n",
        "def download_images(image_links, download_folder):\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    download_image_partial = partial(download_image, save_folder=download_folder)\n",
        "    with multiprocessing.Pool(64) as pool:\n",
        "        list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "\n",
        "# Preprocess text (lowercase, handle common OCR errors)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower().replace(\"o\", \"0\")\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s.,]', '', text)\n",
        "    return text\n",
        "\n",
        "# Extract units from text based on entity type\n",
        "def extract_units(text, entity_name):\n",
        "    extracted_units = set()\n",
        "    cleaned_text = preprocess_text(text)\n",
        "\n",
        "    if entity_name in entity_unit_map:\n",
        "        for unit in entity_unit_map[entity_name]:\n",
        "            if unit in patterns:\n",
        "                matches = re.findall(patterns[unit], cleaned_text)\n",
        "                for match in matches:\n",
        "                    value = float(match[0])\n",
        "                    extracted_units.add(f\"{value} {unit}\")\n",
        "    return extracted_units\n",
        "\n",
        "# Perform OCR and extract best text by rotating image\n",
        "def rotate_and_extract(image):\n",
        "    best_text, best_angle = \"\", 0\n",
        "    for angle in [0, 90, 180, 270]:\n",
        "        rotated_img = image.rotate(angle, expand=True)\n",
        "        rotated_img_np = np.array(rotated_img)\n",
        "        img_text = reader.readtext(rotated_img_np)\n",
        "        final_text = \" \".join([text for _, text, __ in img_text])\n",
        "        if len(final_text.strip()) > len(best_text.strip()):\n",
        "            best_text, best_angle = final_text, angle\n",
        "    return best_text, best_angle\n",
        "\n",
        "# Process image URL\n",
        "def process_image_url(image_url, entity_name, download_folder):\n",
        "    # Download and open image\n",
        "    filename = Path(image_url).name\n",
        "    image_path = os.path.join(download_folder, filename)\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Extract text using OCR and find best rotation\n",
        "    final_text, best_angle = rotate_and_extract(image)\n",
        "\n",
        "    # Extract units\n",
        "    units = extract_units(final_text, entity_name)\n",
        "    return final_text, best_angle, units\n",
        "\n",
        "# Load CSV file (replace with your path)\n",
        "csv_file_path = '/kaggle/input/amazon-dataset/student_resource 3/dataset/train.csv'\n",
        "df = pd.read_csv(csv_file_path).head(500)  # Process first 100 links\n",
        "\n",
        "# Image folder to save the downloaded images\n",
        "download_folder = \"downloaded_images\"\n",
        "\n",
        "# Download images in parallel\n",
        "print(\"Starting image download...\")\n",
        "download_images(df['image_link'], download_folder)\n",
        "\n",
        "# Initialize list to store results\n",
        "results = []\n",
        "\n",
        "# Start tracking time\n",
        "start_time = time.time()\n",
        "\n",
        "# Process each image and extract relevant data\n",
        "for index, row in df.iterrows():\n",
        "    image_url = row['image_link']\n",
        "    entity_name = row['entity_name']\n",
        "\n",
        "    # Process image to get text, angle, and units\n",
        "    final_text, best_angle, units = process_image_url(image_url, entity_name, download_folder)\n",
        "\n",
        "    # Add results\n",
        "    result_row = {\n",
        "        'image_link': image_url,\n",
        "        'entity_name': entity_name,\n",
        "        'extracted_text': final_text,\n",
        "        'best_angle': best_angle,\n",
        "        'predicted': list(units)\n",
        "    }\n",
        "    results.append(result_row)\n",
        "\n",
        "    # Calculate elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "    remaining_images = len(df) - (index + 1)\n",
        "    estimated_total_time = (elapsed_time / (index + 1)) * len(df)\n",
        "    remaining_time = estimated_total_time - elapsed_time\n",
        "\n",
        "    # Print countdown\n",
        "    print(f\"Processed {index + 1}/{len(df)} images. Estimated time remaining: {remaining_time // 60:.0f}m {remaining_time % 60:.0f}s\")\n",
        "\n",
        "# Create DataFrame and save results to CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('predicted_units.csv', index=False)\n",
        "\n",
        "print(f\"Processed {len(results)} images.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T03:50:44.378854Z",
          "iopub.execute_input": "2024-09-16T03:50:44.379257Z",
          "iopub.status.idle": "2024-09-16T04:31:23.938853Z",
          "shell.execute_reply.started": "2024-09-16T03:50:44.379217Z",
          "shell.execute_reply": "2024-09-16T04:31:23.937668Z"
        },
        "trusted": true,
        "id": "MZTrshVtmz1-",
        "outputId": "abe6625d-29e7-4355-b99d-4ab46436600d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting image download...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 500/500 [00:04<00:00, 119.91it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Processed 1/500 images. Estimated time remaining: 56m 23s\nProcessed 2/500 images. Estimated time remaining: 37m 31s\nProcessed 3/500 images. Estimated time remaining: 38m 43s\nProcessed 4/500 images. Estimated time remaining: 41m 14s\nProcessed 5/500 images. Estimated time remaining: 37m 14s\nProcessed 6/500 images. Estimated time remaining: 35m 46s\nProcessed 7/500 images. Estimated time remaining: 47m 6s\nProcessed 8/500 images. Estimated time remaining: 44m 39s\nProcessed 9/500 images. Estimated time remaining: 46m 46s\nProcessed 10/500 images. Estimated time remaining: 45m 6s\nProcessed 11/500 images. Estimated time remaining: 43m 28s\nProcessed 12/500 images. Estimated time remaining: 41m 0s\nProcessed 13/500 images. Estimated time remaining: 44m 28s\nProcessed 14/500 images. Estimated time remaining: 45m 49s\nProcessed 15/500 images. Estimated time remaining: 63m 48s\nProcessed 16/500 images. Estimated time remaining: 65m 24s\nProcessed 17/500 images. Estimated time remaining: 63m 25s\nProcessed 18/500 images. Estimated time remaining: 64m 50s\nProcessed 19/500 images. Estimated time remaining: 64m 59s\nProcessed 20/500 images. Estimated time remaining: 64m 59s\nProcessed 21/500 images. Estimated time remaining: 61m 51s\nProcessed 22/500 images. Estimated time remaining: 60m 4s\nProcessed 23/500 images. Estimated time remaining: 58m 9s\nProcessed 24/500 images. Estimated time remaining: 59m 2s\nProcessed 25/500 images. Estimated time remaining: 57m 49s\nProcessed 26/500 images. Estimated time remaining: 56m 42s\nProcessed 27/500 images. Estimated time remaining: 55m 5s\nProcessed 28/500 images. Estimated time remaining: 53m 16s\nProcessed 29/500 images. Estimated time remaining: 52m 15s\nProcessed 30/500 images. Estimated time remaining: 51m 46s\nProcessed 31/500 images. Estimated time remaining: 52m 25s\nProcessed 32/500 images. Estimated time remaining: 53m 41s\nProcessed 33/500 images. Estimated time remaining: 53m 57s\nProcessed 34/500 images. Estimated time remaining: 54m 33s\nProcessed 35/500 images. Estimated time remaining: 53m 23s\nProcessed 36/500 images. Estimated time remaining: 52m 8s\nProcessed 37/500 images. Estimated time remaining: 50m 54s\nProcessed 38/500 images. Estimated time remaining: 49m 44s\nProcessed 39/500 images. Estimated time remaining: 49m 20s\nProcessed 40/500 images. Estimated time remaining: 49m 19s\nProcessed 41/500 images. Estimated time remaining: 48m 37s\nProcessed 42/500 images. Estimated time remaining: 49m 56s\nProcessed 43/500 images. Estimated time remaining: 49m 5s\nProcessed 44/500 images. Estimated time remaining: 48m 21s\nProcessed 45/500 images. Estimated time remaining: 47m 40s\nProcessed 46/500 images. Estimated time remaining: 46m 59s\nProcessed 47/500 images. Estimated time remaining: 46m 2s\nProcessed 48/500 images. Estimated time remaining: 45m 39s\nProcessed 49/500 images. Estimated time remaining: 45m 51s\nProcessed 50/500 images. Estimated time remaining: 45m 8s\nProcessed 51/500 images. Estimated time remaining: 44m 37s\nProcessed 52/500 images. Estimated time remaining: 44m 16s\nProcessed 53/500 images. Estimated time remaining: 43m 48s\nProcessed 54/500 images. Estimated time remaining: 43m 12s\nProcessed 55/500 images. Estimated time remaining: 43m 8s\nProcessed 56/500 images. Estimated time remaining: 42m 38s\nProcessed 57/500 images. Estimated time remaining: 42m 10s\nProcessed 58/500 images. Estimated time remaining: 42m 4s\nProcessed 59/500 images. Estimated time remaining: 41m 39s\nProcessed 60/500 images. Estimated time remaining: 41m 20s\nProcessed 61/500 images. Estimated time remaining: 41m 1s\nProcessed 62/500 images. Estimated time remaining: 41m 23s\nProcessed 63/500 images. Estimated time remaining: 40m 56s\nProcessed 64/500 images. Estimated time remaining: 40m 54s\nProcessed 65/500 images. Estimated time remaining: 40m 51s\nProcessed 66/500 images. Estimated time remaining: 40m 58s\nProcessed 67/500 images. Estimated time remaining: 40m 60s\nProcessed 68/500 images. Estimated time remaining: 40m 44s\nProcessed 69/500 images. Estimated time remaining: 40m 22s\nProcessed 70/500 images. Estimated time remaining: 40m 5s\nProcessed 71/500 images. Estimated time remaining: 39m 31s\nProcessed 72/500 images. Estimated time remaining: 38m 56s\nProcessed 73/500 images. Estimated time remaining: 38m 25s\nProcessed 74/500 images. Estimated time remaining: 38m 8s\nProcessed 75/500 images. Estimated time remaining: 38m 6s\nProcessed 76/500 images. Estimated time remaining: 38m 7s\nProcessed 77/500 images. Estimated time remaining: 38m 12s\nProcessed 78/500 images. Estimated time remaining: 38m 14s\nProcessed 79/500 images. Estimated time remaining: 38m 30s\nProcessed 80/500 images. Estimated time remaining: 38m 7s\nProcessed 81/500 images. Estimated time remaining: 37m 42s\nProcessed 82/500 images. Estimated time remaining: 37m 19s\nProcessed 83/500 images. Estimated time remaining: 37m 8s\nProcessed 84/500 images. Estimated time remaining: 37m 7s\nProcessed 85/500 images. Estimated time remaining: 37m 18s\nProcessed 86/500 images. Estimated time remaining: 36m 52s\nProcessed 87/500 images. Estimated time remaining: 36m 52s\nProcessed 88/500 images. Estimated time remaining: 36m 33s\nProcessed 89/500 images. Estimated time remaining: 36m 9s\nProcessed 90/500 images. Estimated time remaining: 36m 10s\nProcessed 91/500 images. Estimated time remaining: 36m 11s\nProcessed 92/500 images. Estimated time remaining: 35m 53s\nProcessed 93/500 images. Estimated time remaining: 36m 6s\nProcessed 94/500 images. Estimated time remaining: 36m 1s\nProcessed 95/500 images. Estimated time remaining: 35m 42s\nProcessed 96/500 images. Estimated time remaining: 35m 41s\nProcessed 97/500 images. Estimated time remaining: 35m 26s\nProcessed 98/500 images. Estimated time remaining: 35m 17s\nProcessed 99/500 images. Estimated time remaining: 35m 3s\nProcessed 100/500 images. Estimated time remaining: 34m 46s\nProcessed 101/500 images. Estimated time remaining: 34m 55s\nProcessed 102/500 images. Estimated time remaining: 34m 41s\nProcessed 103/500 images. Estimated time remaining: 34m 42s\nProcessed 104/500 images. Estimated time remaining: 34m 19s\nProcessed 105/500 images. Estimated time remaining: 34m 2s\nProcessed 106/500 images. Estimated time remaining: 33m 48s\nProcessed 107/500 images. Estimated time remaining: 33m 30s\nProcessed 108/500 images. Estimated time remaining: 33m 15s\nProcessed 109/500 images. Estimated time remaining: 33m 17s\nProcessed 110/500 images. Estimated time remaining: 33m 9s\nProcessed 111/500 images. Estimated time remaining: 32m 51s\nProcessed 112/500 images. Estimated time remaining: 32m 40s\nProcessed 113/500 images. Estimated time remaining: 32m 23s\nProcessed 114/500 images. Estimated time remaining: 32m 16s\nProcessed 115/500 images. Estimated time remaining: 32m 6s\nProcessed 116/500 images. Estimated time remaining: 31m 48s\nProcessed 117/500 images. Estimated time remaining: 31m 59s\nProcessed 118/500 images. Estimated time remaining: 32m 11s\nProcessed 119/500 images. Estimated time remaining: 32m 17s\nProcessed 120/500 images. Estimated time remaining: 32m 14s\nProcessed 121/500 images. Estimated time remaining: 32m 22s\nProcessed 122/500 images. Estimated time remaining: 32m 17s\nProcessed 123/500 images. Estimated time remaining: 32m 11s\nProcessed 124/500 images. Estimated time remaining: 31m 59s\nProcessed 125/500 images. Estimated time remaining: 31m 44s\nProcessed 126/500 images. Estimated time remaining: 31m 30s\nProcessed 127/500 images. Estimated time remaining: 31m 20s\nProcessed 128/500 images. Estimated time remaining: 31m 11s\nProcessed 129/500 images. Estimated time remaining: 30m 57s\nProcessed 130/500 images. Estimated time remaining: 30m 42s\nProcessed 131/500 images. Estimated time remaining: 30m 28s\nProcessed 132/500 images. Estimated time remaining: 30m 15s\nProcessed 133/500 images. Estimated time remaining: 30m 15s\nProcessed 134/500 images. Estimated time remaining: 30m 18s\nProcessed 135/500 images. Estimated time remaining: 30m 24s\nProcessed 136/500 images. Estimated time remaining: 30m 25s\nProcessed 137/500 images. Estimated time remaining: 30m 32s\nProcessed 138/500 images. Estimated time remaining: 30m 32s\nProcessed 139/500 images. Estimated time remaining: 30m 22s\nProcessed 140/500 images. Estimated time remaining: 30m 12s\nProcessed 141/500 images. Estimated time remaining: 29m 56s\nProcessed 142/500 images. Estimated time remaining: 29m 46s\nProcessed 143/500 images. Estimated time remaining: 29m 32s\nProcessed 144/500 images. Estimated time remaining: 29m 25s\nProcessed 145/500 images. Estimated time remaining: 29m 14s\nProcessed 146/500 images. Estimated time remaining: 29m 5s\nProcessed 147/500 images. Estimated time remaining: 28m 55s\nProcessed 148/500 images. Estimated time remaining: 28m 54s\nProcessed 149/500 images. Estimated time remaining: 28m 44s\nProcessed 150/500 images. Estimated time remaining: 28m 51s\nProcessed 151/500 images. Estimated time remaining: 28m 41s\nProcessed 152/500 images. Estimated time remaining: 28m 30s\nProcessed 153/500 images. Estimated time remaining: 28m 29s\nProcessed 154/500 images. Estimated time remaining: 28m 24s\nProcessed 155/500 images. Estimated time remaining: 28m 15s\nProcessed 156/500 images. Estimated time remaining: 28m 0s\nProcessed 157/500 images. Estimated time remaining: 27m 51s\nProcessed 158/500 images. Estimated time remaining: 27m 54s\nProcessed 159/500 images. Estimated time remaining: 27m 47s\nProcessed 160/500 images. Estimated time remaining: 27m 38s\nProcessed 161/500 images. Estimated time remaining: 27m 25s\nProcessed 162/500 images. Estimated time remaining: 27m 18s\nProcessed 163/500 images. Estimated time remaining: 27m 6s\nProcessed 164/500 images. Estimated time remaining: 26m 56s\nProcessed 165/500 images. Estimated time remaining: 26m 43s\nProcessed 166/500 images. Estimated time remaining: 26m 38s\nProcessed 167/500 images. Estimated time remaining: 26m 28s\nProcessed 168/500 images. Estimated time remaining: 26m 21s\nProcessed 169/500 images. Estimated time remaining: 26m 10s\nProcessed 170/500 images. Estimated time remaining: 26m 1s\nProcessed 171/500 images. Estimated time remaining: 26m 0s\nProcessed 172/500 images. Estimated time remaining: 25m 57s\nProcessed 173/500 images. Estimated time remaining: 25m 55s\nProcessed 174/500 images. Estimated time remaining: 25m 53s\nProcessed 175/500 images. Estimated time remaining: 25m 51s\nProcessed 176/500 images. Estimated time remaining: 25m 57s\nProcessed 177/500 images. Estimated time remaining: 25m 54s\nProcessed 178/500 images. Estimated time remaining: 25m 50s\nProcessed 179/500 images. Estimated time remaining: 25m 38s\nProcessed 180/500 images. Estimated time remaining: 25m 38s\nProcessed 181/500 images. Estimated time remaining: 25m 37s\nProcessed 182/500 images. Estimated time remaining: 25m 30s\nProcessed 183/500 images. Estimated time remaining: 25m 21s\nProcessed 184/500 images. Estimated time remaining: 25m 12s\nProcessed 185/500 images. Estimated time remaining: 25m 3s\nProcessed 186/500 images. Estimated time remaining: 24m 55s\nProcessed 187/500 images. Estimated time remaining: 24m 49s\nProcessed 188/500 images. Estimated time remaining: 24m 39s\nProcessed 189/500 images. Estimated time remaining: 24m 33s\nProcessed 190/500 images. Estimated time remaining: 24m 40s\nProcessed 191/500 images. Estimated time remaining: 24m 50s\nProcessed 192/500 images. Estimated time remaining: 24m 41s\nProcessed 193/500 images. Estimated time remaining: 24m 40s\nProcessed 194/500 images. Estimated time remaining: 24m 34s\nProcessed 195/500 images. Estimated time remaining: 24m 37s\nProcessed 196/500 images. Estimated time remaining: 24m 33s\nProcessed 197/500 images. Estimated time remaining: 24m 33s\nProcessed 198/500 images. Estimated time remaining: 24m 31s\nProcessed 199/500 images. Estimated time remaining: 24m 19s\nProcessed 200/500 images. Estimated time remaining: 24m 19s\nProcessed 201/500 images. Estimated time remaining: 24m 15s\nProcessed 202/500 images. Estimated time remaining: 24m 8s\nProcessed 203/500 images. Estimated time remaining: 24m 1s\nProcessed 204/500 images. Estimated time remaining: 23m 54s\nProcessed 205/500 images. Estimated time remaining: 23m 45s\nProcessed 206/500 images. Estimated time remaining: 23m 39s\nProcessed 207/500 images. Estimated time remaining: 24m 20s\nProcessed 208/500 images. Estimated time remaining: 24m 32s\nProcessed 209/500 images. Estimated time remaining: 24m 34s\nProcessed 210/500 images. Estimated time remaining: 24m 44s\nProcessed 211/500 images. Estimated time remaining: 24m 43s\nProcessed 212/500 images. Estimated time remaining: 24m 48s\nProcessed 213/500 images. Estimated time remaining: 24m 39s\nProcessed 214/500 images. Estimated time remaining: 24m 32s\nProcessed 215/500 images. Estimated time remaining: 24m 23s\nProcessed 216/500 images. Estimated time remaining: 24m 15s\nProcessed 217/500 images. Estimated time remaining: 24m 7s\nProcessed 218/500 images. Estimated time remaining: 23m 60s\nProcessed 219/500 images. Estimated time remaining: 23m 52s\nProcessed 220/500 images. Estimated time remaining: 23m 44s\nProcessed 221/500 images. Estimated time remaining: 23m 34s\nProcessed 222/500 images. Estimated time remaining: 23m 31s\nProcessed 223/500 images. Estimated time remaining: 23m 23s\nProcessed 224/500 images. Estimated time remaining: 23m 14s\nProcessed 225/500 images. Estimated time remaining: 23m 9s\nProcessed 226/500 images. Estimated time remaining: 23m 2s\nProcessed 227/500 images. Estimated time remaining: 22m 55s\nProcessed 228/500 images. Estimated time remaining: 22m 52s\nProcessed 229/500 images. Estimated time remaining: 22m 45s\nProcessed 230/500 images. Estimated time remaining: 22m 39s\nProcessed 231/500 images. Estimated time remaining: 22m 37s\nProcessed 232/500 images. Estimated time remaining: 22m 28s\nProcessed 233/500 images. Estimated time remaining: 22m 30s\nProcessed 234/500 images. Estimated time remaining: 22m 38s\nProcessed 235/500 images. Estimated time remaining: 22m 34s\nProcessed 236/500 images. Estimated time remaining: 22m 31s\nProcessed 237/500 images. Estimated time remaining: 22m 22s\nProcessed 238/500 images. Estimated time remaining: 22m 13s\nProcessed 239/500 images. Estimated time remaining: 22m 7s\nProcessed 240/500 images. Estimated time remaining: 21m 58s\nProcessed 241/500 images. Estimated time remaining: 21m 50s\nProcessed 242/500 images. Estimated time remaining: 21m 41s\nProcessed 243/500 images. Estimated time remaining: 21m 32s\nProcessed 244/500 images. Estimated time remaining: 21m 24s\nProcessed 245/500 images. Estimated time remaining: 21m 16s\nProcessed 246/500 images. Estimated time remaining: 21m 9s\nProcessed 247/500 images. Estimated time remaining: 21m 0s\nProcessed 248/500 images. Estimated time remaining: 20m 58s\nProcessed 249/500 images. Estimated time remaining: 20m 54s\nProcessed 250/500 images. Estimated time remaining: 20m 47s\nProcessed 251/500 images. Estimated time remaining: 20m 41s\nProcessed 252/500 images. Estimated time remaining: 20m 48s\nProcessed 253/500 images. Estimated time remaining: 20m 54s\nProcessed 254/500 images. Estimated time remaining: 20m 48s\nProcessed 255/500 images. Estimated time remaining: 20m 43s\nProcessed 256/500 images. Estimated time remaining: 20m 43s\nProcessed 257/500 images. Estimated time remaining: 20m 42s\nProcessed 258/500 images. Estimated time remaining: 20m 54s\nProcessed 259/500 images. Estimated time remaining: 20m 48s\nProcessed 260/500 images. Estimated time remaining: 20m 40s\nProcessed 261/500 images. Estimated time remaining: 20m 34s\nProcessed 262/500 images. Estimated time remaining: 20m 31s\nProcessed 263/500 images. Estimated time remaining: 20m 22s\nProcessed 264/500 images. Estimated time remaining: 20m 16s\nProcessed 265/500 images. Estimated time remaining: 20m 11s\nProcessed 266/500 images. Estimated time remaining: 20m 6s\nProcessed 267/500 images. Estimated time remaining: 19m 60s\nProcessed 268/500 images. Estimated time remaining: 19m 54s\nProcessed 269/500 images. Estimated time remaining: 19m 59s\nProcessed 270/500 images. Estimated time remaining: 19m 53s\nProcessed 271/500 images. Estimated time remaining: 19m 44s\nProcessed 272/500 images. Estimated time remaining: 19m 36s\nProcessed 273/500 images. Estimated time remaining: 19m 28s\nProcessed 274/500 images. Estimated time remaining: 19m 21s\nProcessed 275/500 images. Estimated time remaining: 19m 13s\nProcessed 276/500 images. Estimated time remaining: 19m 8s\nProcessed 277/500 images. Estimated time remaining: 19m 4s\nProcessed 278/500 images. Estimated time remaining: 18m 56s\nProcessed 279/500 images. Estimated time remaining: 18m 47s\nProcessed 280/500 images. Estimated time remaining: 18m 41s\nProcessed 281/500 images. Estimated time remaining: 18m 33s\nProcessed 282/500 images. Estimated time remaining: 18m 24s\nProcessed 283/500 images. Estimated time remaining: 18m 19s\nProcessed 284/500 images. Estimated time remaining: 18m 17s\nProcessed 285/500 images. Estimated time remaining: 18m 11s\nProcessed 286/500 images. Estimated time remaining: 18m 5s\nProcessed 287/500 images. Estimated time remaining: 17m 57s\nProcessed 288/500 images. Estimated time remaining: 17m 51s\nProcessed 289/500 images. Estimated time remaining: 17m 45s\nProcessed 290/500 images. Estimated time remaining: 17m 38s\nProcessed 291/500 images. Estimated time remaining: 17m 32s\nProcessed 292/500 images. Estimated time remaining: 17m 25s\nProcessed 293/500 images. Estimated time remaining: 17m 18s\nProcessed 294/500 images. Estimated time remaining: 17m 11s\nProcessed 295/500 images. Estimated time remaining: 17m 5s\nProcessed 296/500 images. Estimated time remaining: 16m 59s\nProcessed 297/500 images. Estimated time remaining: 16m 53s\nProcessed 298/500 images. Estimated time remaining: 16m 47s\nProcessed 299/500 images. Estimated time remaining: 16m 43s\nProcessed 300/500 images. Estimated time remaining: 16m 48s\nProcessed 301/500 images. Estimated time remaining: 16m 42s\nProcessed 302/500 images. Estimated time remaining: 16m 36s\nProcessed 303/500 images. Estimated time remaining: 16m 30s\nProcessed 304/500 images. Estimated time remaining: 16m 25s\nProcessed 305/500 images. Estimated time remaining: 16m 18s\nProcessed 306/500 images. Estimated time remaining: 16m 11s\nProcessed 307/500 images. Estimated time remaining: 16m 5s\nProcessed 308/500 images. Estimated time remaining: 15m 58s\nProcessed 309/500 images. Estimated time remaining: 15m 52s\nProcessed 310/500 images. Estimated time remaining: 15m 48s\nProcessed 311/500 images. Estimated time remaining: 15m 45s\nProcessed 312/500 images. Estimated time remaining: 15m 39s\nProcessed 313/500 images. Estimated time remaining: 15m 34s\nProcessed 314/500 images. Estimated time remaining: 15m 29s\nProcessed 315/500 images. Estimated time remaining: 15m 22s\nProcessed 316/500 images. Estimated time remaining: 15m 15s\nProcessed 317/500 images. Estimated time remaining: 15m 8s\nProcessed 318/500 images. Estimated time remaining: 15m 1s\nProcessed 319/500 images. Estimated time remaining: 14m 58s\nProcessed 320/500 images. Estimated time remaining: 14m 55s\nProcessed 321/500 images. Estimated time remaining: 14m 57s\nProcessed 322/500 images. Estimated time remaining: 14m 56s\nProcessed 323/500 images. Estimated time remaining: 14m 51s\nProcessed 324/500 images. Estimated time remaining: 14m 50s\nProcessed 325/500 images. Estimated time remaining: 14m 43s\nProcessed 326/500 images. Estimated time remaining: 14m 37s\nProcessed 327/500 images. Estimated time remaining: 14m 30s\nProcessed 328/500 images. Estimated time remaining: 14m 25s\nProcessed 329/500 images. Estimated time remaining: 14m 20s\nProcessed 330/500 images. Estimated time remaining: 14m 18s\nProcessed 331/500 images. Estimated time remaining: 14m 14s\nProcessed 332/500 images. Estimated time remaining: 14m 11s\nProcessed 333/500 images. Estimated time remaining: 14m 8s\nProcessed 334/500 images. Estimated time remaining: 14m 4s\nProcessed 335/500 images. Estimated time remaining: 14m 2s\nProcessed 336/500 images. Estimated time remaining: 13m 58s\nProcessed 337/500 images. Estimated time remaining: 13m 53s\nProcessed 338/500 images. Estimated time remaining: 13m 48s\nProcessed 339/500 images. Estimated time remaining: 13m 43s\nProcessed 340/500 images. Estimated time remaining: 13m 38s\nProcessed 341/500 images. Estimated time remaining: 13m 31s\nProcessed 342/500 images. Estimated time remaining: 13m 25s\nProcessed 343/500 images. Estimated time remaining: 13m 17s\nProcessed 344/500 images. Estimated time remaining: 13m 13s\nProcessed 345/500 images. Estimated time remaining: 13m 7s\nProcessed 346/500 images. Estimated time remaining: 13m 4s\nProcessed 347/500 images. Estimated time remaining: 12m 58s\nProcessed 348/500 images. Estimated time remaining: 12m 53s\nProcessed 349/500 images. Estimated time remaining: 12m 48s\nProcessed 350/500 images. Estimated time remaining: 12m 41s\nProcessed 351/500 images. Estimated time remaining: 12m 36s\nProcessed 352/500 images. Estimated time remaining: 12m 30s\nProcessed 353/500 images. Estimated time remaining: 12m 24s\nProcessed 354/500 images. Estimated time remaining: 12m 18s\nProcessed 355/500 images. Estimated time remaining: 12m 14s\nProcessed 356/500 images. Estimated time remaining: 12m 9s\nProcessed 357/500 images. Estimated time remaining: 12m 2s\nProcessed 358/500 images. Estimated time remaining: 11m 56s\nProcessed 359/500 images. Estimated time remaining: 11m 50s\nProcessed 360/500 images. Estimated time remaining: 11m 44s\nProcessed 361/500 images. Estimated time remaining: 11m 37s\nProcessed 362/500 images. Estimated time remaining: 11m 31s\nProcessed 363/500 images. Estimated time remaining: 11m 27s\nProcessed 364/500 images. Estimated time remaining: 11m 21s\nProcessed 365/500 images. Estimated time remaining: 11m 15s\nProcessed 366/500 images. Estimated time remaining: 11m 10s\nProcessed 367/500 images. Estimated time remaining: 11m 6s\nProcessed 368/500 images. Estimated time remaining: 10m 59s\nProcessed 369/500 images. Estimated time remaining: 10m 55s\nProcessed 370/500 images. Estimated time remaining: 10m 52s\nProcessed 371/500 images. Estimated time remaining: 10m 45s\nProcessed 372/500 images. Estimated time remaining: 10m 39s\nProcessed 373/500 images. Estimated time remaining: 10m 34s\nProcessed 374/500 images. Estimated time remaining: 10m 28s\nProcessed 375/500 images. Estimated time remaining: 10m 23s\nProcessed 376/500 images. Estimated time remaining: 10m 19s\nProcessed 377/500 images. Estimated time remaining: 10m 18s\nProcessed 378/500 images. Estimated time remaining: 10m 12s\nProcessed 379/500 images. Estimated time remaining: 10m 7s\nProcessed 380/500 images. Estimated time remaining: 10m 1s\nProcessed 381/500 images. Estimated time remaining: 9m 55s\nProcessed 382/500 images. Estimated time remaining: 9m 49s\nProcessed 383/500 images. Estimated time remaining: 9m 42s\nProcessed 384/500 images. Estimated time remaining: 9m 37s\nProcessed 385/500 images. Estimated time remaining: 9m 31s\nProcessed 386/500 images. Estimated time remaining: 9m 26s\nProcessed 387/500 images. Estimated time remaining: 9m 22s\nProcessed 388/500 images. Estimated time remaining: 9m 18s\nProcessed 389/500 images. Estimated time remaining: 9m 12s\nProcessed 390/500 images. Estimated time remaining: 9m 7s\nProcessed 391/500 images. Estimated time remaining: 9m 1s\nProcessed 392/500 images. Estimated time remaining: 8m 56s\nProcessed 393/500 images. Estimated time remaining: 8m 50s\nProcessed 394/500 images. Estimated time remaining: 8m 46s\nProcessed 395/500 images. Estimated time remaining: 8m 40s\nProcessed 396/500 images. Estimated time remaining: 8m 35s\nProcessed 397/500 images. Estimated time remaining: 8m 30s\nProcessed 398/500 images. Estimated time remaining: 8m 24s\nProcessed 399/500 images. Estimated time remaining: 8m 20s\nProcessed 400/500 images. Estimated time remaining: 8m 15s\nProcessed 401/500 images. Estimated time remaining: 8m 10s\nProcessed 402/500 images. Estimated time remaining: 8m 5s\nProcessed 403/500 images. Estimated time remaining: 7m 60s\nProcessed 404/500 images. Estimated time remaining: 7m 54s\nProcessed 405/500 images. Estimated time remaining: 7m 48s\nProcessed 406/500 images. Estimated time remaining: 7m 43s\nProcessed 407/500 images. Estimated time remaining: 7m 38s\nProcessed 408/500 images. Estimated time remaining: 7m 33s\nProcessed 409/500 images. Estimated time remaining: 7m 28s\nProcessed 410/500 images. Estimated time remaining: 7m 23s\nProcessed 411/500 images. Estimated time remaining: 7m 17s\nProcessed 412/500 images. Estimated time remaining: 7m 12s\nProcessed 413/500 images. Estimated time remaining: 7m 6s\nProcessed 414/500 images. Estimated time remaining: 7m 2s\nProcessed 415/500 images. Estimated time remaining: 6m 57s\nProcessed 416/500 images. Estimated time remaining: 6m 52s\nProcessed 417/500 images. Estimated time remaining: 6m 47s\nProcessed 418/500 images. Estimated time remaining: 6m 42s\nProcessed 419/500 images. Estimated time remaining: 6m 37s\nProcessed 420/500 images. Estimated time remaining: 6m 32s\nProcessed 421/500 images. Estimated time remaining: 6m 26s\nProcessed 422/500 images. Estimated time remaining: 6m 21s\nProcessed 423/500 images. Estimated time remaining: 6m 15s\nProcessed 424/500 images. Estimated time remaining: 6m 10s\nProcessed 425/500 images. Estimated time remaining: 6m 4s\nProcessed 426/500 images. Estimated time remaining: 5m 59s\nProcessed 427/500 images. Estimated time remaining: 5m 54s\nProcessed 428/500 images. Estimated time remaining: 5m 51s\nProcessed 429/500 images. Estimated time remaining: 5m 46s\nProcessed 430/500 images. Estimated time remaining: 5m 41s\nProcessed 431/500 images. Estimated time remaining: 5m 36s\nProcessed 432/500 images. Estimated time remaining: 5m 31s\nProcessed 433/500 images. Estimated time remaining: 5m 26s\nProcessed 434/500 images. Estimated time remaining: 5m 23s\nProcessed 435/500 images. Estimated time remaining: 5m 20s\nProcessed 436/500 images. Estimated time remaining: 5m 16s\nProcessed 437/500 images. Estimated time remaining: 5m 11s\nProcessed 438/500 images. Estimated time remaining: 5m 6s\nProcessed 439/500 images. Estimated time remaining: 5m 1s\nProcessed 440/500 images. Estimated time remaining: 4m 56s\nProcessed 441/500 images. Estimated time remaining: 4m 51s\nProcessed 442/500 images. Estimated time remaining: 4m 45s\nProcessed 443/500 images. Estimated time remaining: 4m 40s\nProcessed 444/500 images. Estimated time remaining: 4m 35s\nProcessed 445/500 images. Estimated time remaining: 4m 30s\nProcessed 446/500 images. Estimated time remaining: 4m 26s\nProcessed 447/500 images. Estimated time remaining: 4m 21s\nProcessed 448/500 images. Estimated time remaining: 4m 17s\nProcessed 449/500 images. Estimated time remaining: 4m 12s\nProcessed 450/500 images. Estimated time remaining: 4m 7s\nProcessed 451/500 images. Estimated time remaining: 4m 2s\nProcessed 452/500 images. Estimated time remaining: 3m 57s\nProcessed 453/500 images. Estimated time remaining: 3m 52s\nProcessed 454/500 images. Estimated time remaining: 3m 47s\nProcessed 455/500 images. Estimated time remaining: 3m 42s\nProcessed 456/500 images. Estimated time remaining: 3m 37s\nProcessed 457/500 images. Estimated time remaining: 3m 32s\nProcessed 458/500 images. Estimated time remaining: 3m 27s\nProcessed 459/500 images. Estimated time remaining: 3m 22s\nProcessed 460/500 images. Estimated time remaining: 3m 17s\nProcessed 461/500 images. Estimated time remaining: 3m 12s\nProcessed 462/500 images. Estimated time remaining: 3m 7s\nProcessed 463/500 images. Estimated time remaining: 3m 2s\nProcessed 464/500 images. Estimated time remaining: 2m 57s\nProcessed 465/500 images. Estimated time remaining: 2m 52s\nProcessed 466/500 images. Estimated time remaining: 2m 47s\nProcessed 467/500 images. Estimated time remaining: 2m 42s\nProcessed 468/500 images. Estimated time remaining: 2m 37s\nProcessed 469/500 images. Estimated time remaining: 2m 32s\nProcessed 470/500 images. Estimated time remaining: 2m 27s\nProcessed 471/500 images. Estimated time remaining: 2m 22s\nProcessed 472/500 images. Estimated time remaining: 2m 17s\nProcessed 473/500 images. Estimated time remaining: 2m 12s\nProcessed 474/500 images. Estimated time remaining: 2m 7s\nProcessed 475/500 images. Estimated time remaining: 2m 2s\nProcessed 476/500 images. Estimated time remaining: 1m 57s\nProcessed 477/500 images. Estimated time remaining: 1m 52s\nProcessed 478/500 images. Estimated time remaining: 1m 47s\nProcessed 479/500 images. Estimated time remaining: 1m 42s\nProcessed 480/500 images. Estimated time remaining: 1m 37s\nProcessed 481/500 images. Estimated time remaining: 1m 32s\nProcessed 482/500 images. Estimated time remaining: 1m 27s\nProcessed 483/500 images. Estimated time remaining: 1m 23s\nProcessed 484/500 images. Estimated time remaining: 1m 18s\nProcessed 485/500 images. Estimated time remaining: 1m 13s\nProcessed 486/500 images. Estimated time remaining: 1m 8s\nProcessed 487/500 images. Estimated time remaining: 1m 3s\nProcessed 488/500 images. Estimated time remaining: 0m 59s\nProcessed 489/500 images. Estimated time remaining: 0m 54s\nProcessed 490/500 images. Estimated time remaining: 0m 49s\nProcessed 491/500 images. Estimated time remaining: 0m 44s\nProcessed 492/500 images. Estimated time remaining: 0m 39s\nProcessed 493/500 images. Estimated time remaining: 0m 34s\nProcessed 494/500 images. Estimated time remaining: 0m 29s\nProcessed 495/500 images. Estimated time remaining: 0m 24s\nProcessed 496/500 images. Estimated time remaining: 0m 19s\nProcessed 497/500 images. Estimated time remaining: 0m 15s\nProcessed 498/500 images. Estimated time remaining: 0m 10s\nProcessed 499/500 images. Estimated time remaining: 0m 5s\nProcessed 500/500 images. Estimated time remaining: 0m 0s\nProcessed 500 images.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for model training\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the processed training data\n",
        "train_data = pd.read_csv('predicted_units.csv')\n",
        "\n",
        "# Prepare features (extracted_text) and labels (entity_name)\n",
        "X_train = train_data['extracted_text'].astype(str)  # Ensure all values are strings\n",
        "y_train = train_data['entity_name']\n",
        "\n",
        "# Convert the text data to numerical format using TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Validate the model using validation data\n",
        "y_pred = clf.predict(X_val_split)\n",
        "accuracy = accuracy_score(y_val_split, y_pred)\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Save the trained model and vectorizer for later use\n",
        "joblib.dump(clf, 'trained_model.pkl')\n",
        "joblib.dump(vectorizer, 'vectorizer.pkl')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T04:31:23.9415Z",
          "iopub.execute_input": "2024-09-16T04:31:23.942406Z",
          "iopub.status.idle": "2024-09-16T04:31:26.020393Z",
          "shell.execute_reply.started": "2024-09-16T04:31:23.942359Z",
          "shell.execute_reply": "2024-09-16T04:31:26.019276Z"
        },
        "trusted": true,
        "id": "DgCgMdurmz1-",
        "outputId": "6cee8d2d-541f-4b24-9082-1c61d2ae40d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Validation Accuracy: 0.82\n",
          "output_type": "stream"
        },
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['vectorizer.pkl']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "import easyocr\n",
        "import re\n",
        "import concurrent.futures\n",
        "import time\n",
        "import io\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Load test CSV file\n",
        "test_csv_file_path = '/kaggle/input/amazon-dataset/student_resource 3/dataset/sample_test.csv'\n",
        "test_df = pd.read_csv(test_csv_file_path)\n",
        "\n",
        "# Function to clean misinterpreted values (e.g., \"2OCM 1SCM\" -> \"20cm 1cm\")\n",
        "def correct_misinterpretations(text):\n",
        "    text = text.upper()\n",
        "    text = text.replace(\"O\", \"0\")  # Replace O with 0\n",
        "    text = text.replace(\"SCM\", \"CM\")  # Correct SCM to CM\n",
        "    return text\n",
        "\n",
        "# Updated function to extract units and their values from the text (including misinterpretation handling)\n",
        "def extract_units(text):\n",
        "    text = correct_misinterpretations(text)\n",
        "    patterns = {\n",
        "        'gram': r'(\\d+(\\.\\d+)?)\\s*(g(rams?)?)',\n",
        "        'kilogram': r'(\\d+(\\.\\d+)?)\\s*(kg)',\n",
        "        'milligram': r'(\\d+(\\.\\d+)?)\\s*(mg)',\n",
        "        'microgram': r'(\\d+(\\.\\d+)?)\\s*(µg)',\n",
        "        'ounce': r'(\\d+(\\.\\d+)?)\\s*(oz)',\n",
        "        'pound': r'(\\d+(\\.\\d+)?)\\s*(lb|pounds?)',\n",
        "        'ton': r'(\\d+(\\.\\d+)?)\\s*(ton)',\n",
        "        'centimetre': r'(\\d+(\\.\\d+)?)\\s*(cm)',\n",
        "        'foot': r'(\\d+(\\.\\d+)?)\\s*(ft|feet|foot)',\n",
        "        'inch': r'(\\d+(\\.\\d+)?)\\s*(in(ch)?|\")',\n",
        "        'metre': r'(\\d+(\\.\\d+)?)\\s*(m(etres?)?)',\n",
        "        'millimetre': r'(\\d+(\\.\\d+)?)\\s*(mm)',\n",
        "        'yard': r'(\\d+(\\.\\d+)?)\\s*(yd)',\n",
        "        'kilovolt': r'(\\d+(\\.\\d+)?)\\s*(kv)',\n",
        "        'millivolt': r'(\\d+(\\.\\d+)?)\\s*(mv)',\n",
        "        'volt': r'(\\d+(\\.\\d+)?)\\s*(v)',\n",
        "        'kilowatt': r'(\\d+(\\.\\d+)?)\\s*(kw)',\n",
        "        'watt': r'(\\d+(\\.\\d+)?)\\s*(w)',\n",
        "        'litre': r'(\\d+(\\.\\d+)?)\\s*(l(itres?)?)',\n",
        "        'millilitre': r'(\\d+(\\.\\d+)?)\\s*(ml)'\n",
        "    }\n",
        "    units = set()\n",
        "    text = text.lower()\n",
        "    for unit_name, pattern in patterns.items():\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        for match in matches:\n",
        "            extracted_value = f\"{match[0]} {unit_name}\" if unit_name != 'inch' else f\"{match[0]} inch\"\n",
        "            units.add(extracted_value)\n",
        "    return units\n",
        "\n",
        "# Function to process images directly from URL without saving them\n",
        "def process_image_from_url(image_link):\n",
        "    try:\n",
        "        with urllib.request.urlopen(image_link) as url:\n",
        "            image = Image.open(io.BytesIO(url.read()))\n",
        "        result = reader.readtext(image, detail=0)\n",
        "        final_text = \" \".join(result)\n",
        "        return final_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_link}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to match the extracted units with the entity name\n",
        "def match_units_with_entity(entity_name, extracted_units):\n",
        "    entity_unit_map = {\n",
        "        'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "        'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "        'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "        'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "        'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "        'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "        'wattage': {'kilowatt', 'watt'},\n",
        "        'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "    }\n",
        "    valid_units = entity_unit_map.get(entity_name, set())\n",
        "    relevant_units = [unit for unit in extracted_units if any(valid_unit in unit for valid_unit in valid_units)]\n",
        "    return relevant_units\n",
        "\n",
        "# Function to process each row and return results\n",
        "def process_row(row):\n",
        "    image_url = row['image_link']\n",
        "    entity_name = row['entity_name']\n",
        "    group_id = row['group_id']\n",
        "    final_text = process_image_from_url(image_url)\n",
        "    extracted_units = extract_units(final_text)\n",
        "    matched_units = match_units_with_entity(entity_name, extracted_units)\n",
        "    predicted_value = \", \".join(matched_units) if matched_units else \"\"\n",
        "    return {\n",
        "        'image_link': image_url,\n",
        "        'entity_name': entity_name,\n",
        "        'group_id': group_id,\n",
        "        'extracted_text': final_text,\n",
        "        'predicted_units': matched_units,\n",
        "        'predicted': predicted_value\n",
        "    }\n",
        "\n",
        "# Initialize list to store test results\n",
        "test_results = []\n",
        "\n",
        "# Start tracking time\n",
        "start_time = time.time()\n",
        "\n",
        "# Use ThreadPoolExecutor for concurrent processing\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Process each row in parallel\n",
        "    future_to_row = {executor.submit(process_row, row): row for index, row in test_df.iterrows()}\n",
        "\n",
        "    for index, future in enumerate(concurrent.futures.as_completed(future_to_row)):\n",
        "        try:\n",
        "            result_row = future.result()\n",
        "            test_results.append(result_row)\n",
        "\n",
        "            # Calculate elapsed time and remaining time\n",
        "            elapsed_time = time.time() - start_time\n",
        "            remaining_images = len(test_df) - (index + 1)\n",
        "            estimated_total_time = (elapsed_time / (index + 1)) * len(test_df)\n",
        "            remaining_time = estimated_total_time - elapsed_time\n",
        "\n",
        "            # Print progress\n",
        "            print(f\"Processed {index + 1}/{len(test_df)} test images. Estimated time remaining: {remaining_time // 60:.0f}m {remaining_time % 60:.0f}s\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row: {e}\")\n",
        "\n",
        "# Calculate final elapsed time\n",
        "total_elapsed_time = time.time() - start_time\n",
        "\n",
        "# Create DataFrame and save test results to CSV\n",
        "test_results_df = pd.DataFrame(test_results)\n",
        "test_results_df.to_csv('test_matched_units.csv', index=False)\n",
        "\n",
        "print(f\"Processed {len(test_results)} test images in {total_elapsed_time // 60:.0f}m {total_elapsed_time % 60:.0f}s\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:49:40.968027Z",
          "iopub.execute_input": "2024-09-16T06:49:40.968357Z",
          "iopub.status.idle": "2024-09-16T06:50:24.3931Z",
          "shell.execute_reply.started": "2024-09-16T06:49:40.968318Z",
          "shell.execute_reply": "2024-09-16T06:50:24.392053Z"
        },
        "trusted": true,
        "id": "EVVXHl-pmz1_",
        "outputId": "463fc5cb-1a7d-44f3-cee9-2ed77fe4929d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Processed 1/88 test images. Estimated time remaining: 4m 13s\nProcessed 2/88 test images. Estimated time remaining: 2m 5s\nProcessed 3/88 test images. Estimated time remaining: 1m 23s\nProcessed 4/88 test images. Estimated time remaining: 1m 16s\nProcessed 5/88 test images. Estimated time remaining: 1m 4s\nProcessed 6/88 test images. Estimated time remaining: 0m 54s\nProcessed 7/88 test images. Estimated time remaining: 0m 45s\nProcessed 8/88 test images. Estimated time remaining: 0m 39s\nProcessed 9/88 test images. Estimated time remaining: 0m 48s\nProcessed 10/88 test images. Estimated time remaining: 0m 43s\nProcessed 11/88 test images. Estimated time remaining: 0m 39s\nProcessed 12/88 test images. Estimated time remaining: 0m 35s\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Processed 13/88 test images. Estimated time remaining: 0m 37s\nProcessed 14/88 test images. Estimated time remaining: 0m 37s\nProcessed 15/88 test images. Estimated time remaining: 0m 36s\nProcessed 16/88 test images. Estimated time remaining: 0m 33s\nProcessed 17/88 test images. Estimated time remaining: 0m 31s\nProcessed 18/88 test images. Estimated time remaining: 0m 29s\nProcessed 19/88 test images. Estimated time remaining: 0m 28s\nProcessed 20/88 test images. Estimated time remaining: 0m 27s\nProcessed 21/88 test images. Estimated time remaining: 0m 26s\nProcessed 22/88 test images. Estimated time remaining: 0m 25s\nProcessed 23/88 test images. Estimated time remaining: 0m 25s\nProcessed 24/88 test images. Estimated time remaining: 0m 24s\nProcessed 25/88 test images. Estimated time remaining: 0m 23s\nProcessed 26/88 test images. Estimated time remaining: 0m 22s\nProcessed 27/88 test images. Estimated time remaining: 0m 21s\nProcessed 28/88 test images. Estimated time remaining: 0m 21s\nProcessed 29/88 test images. Estimated time remaining: 0m 20s\nProcessed 30/88 test images. Estimated time remaining: 0m 20s\nProcessed 31/88 test images. Estimated time remaining: 0m 19s\nProcessed 32/88 test images. Estimated time remaining: 0m 19s\nProcessed 33/88 test images. Estimated time remaining: 0m 18s\nProcessed 34/88 test images. Estimated time remaining: 0m 17s\nProcessed 35/88 test images. Estimated time remaining: 0m 17s\nProcessed 36/88 test images. Estimated time remaining: 0m 17s\nProcessed 37/88 test images. Estimated time remaining: 0m 17s\nProcessed 38/88 test images. Estimated time remaining: 0m 16s\nProcessed 39/88 test images. Estimated time remaining: 0m 16s\nProcessed 40/88 test images. Estimated time remaining: 0m 15s\nProcessed 41/88 test images. Estimated time remaining: 0m 15s\nProcessed 42/88 test images. Estimated time remaining: 0m 14s\nProcessed 43/88 test images. Estimated time remaining: 0m 14s\nProcessed 44/88 test images. Estimated time remaining: 0m 13s\nProcessed 45/88 test images. Estimated time remaining: 0m 13s\nProcessed 46/88 test images. Estimated time remaining: 0m 12s\nProcessed 47/88 test images. Estimated time remaining: 0m 12s\nProcessed 48/88 test images. Estimated time remaining: 0m 12s\nProcessed 49/88 test images. Estimated time remaining: 0m 12s\nProcessed 50/88 test images. Estimated time remaining: 0m 11s\nProcessed 51/88 test images. Estimated time remaining: 0m 12s\nProcessed 52/88 test images. Estimated time remaining: 0m 11s\nProcessed 53/88 test images. Estimated time remaining: 0m 11s\nProcessed 54/88 test images. Estimated time remaining: 0m 11s\nProcessed 55/88 test images. Estimated time remaining: 0m 11s\nProcessed 56/88 test images. Estimated time remaining: 0m 10s\nProcessed 57/88 test images. Estimated time remaining: 0m 10s\nProcessed 58/88 test images. Estimated time remaining: 0m 10s\nProcessed 59/88 test images. Estimated time remaining: 0m 9s\nProcessed 60/88 test images. Estimated time remaining: 0m 9s\nProcessed 61/88 test images. Estimated time remaining: 0m 9s\nProcessed 62/88 test images. Estimated time remaining: 0m 9s\nProcessed 63/88 test images. Estimated time remaining: 0m 9s\nProcessed 64/88 test images. Estimated time remaining: 0m 8s\nProcessed 65/88 test images. Estimated time remaining: 0m 8s\nProcessed 66/88 test images. Estimated time remaining: 0m 8s\nProcessed 67/88 test images. Estimated time remaining: 0m 8s\nProcessed 68/88 test images. Estimated time remaining: 0m 7s\nProcessed 69/88 test images. Estimated time remaining: 0m 7s\nProcessed 70/88 test images. Estimated time remaining: 0m 6s\nProcessed 71/88 test images. Estimated time remaining: 0m 6s\nProcessed 72/88 test images. Estimated time remaining: 0m 6s\nProcessed 73/88 test images. Estimated time remaining: 0m 5s\nProcessed 74/88 test images. Estimated time remaining: 0m 5s\nProcessed 75/88 test images. Estimated time remaining: 0m 5s\nProcessed 76/88 test images. Estimated time remaining: 0m 5s\nProcessed 77/88 test images. Estimated time remaining: 0m 4s\nProcessed 78/88 test images. Estimated time remaining: 0m 4s\nProcessed 79/88 test images. Estimated time remaining: 0m 3s\nProcessed 80/88 test images. Estimated time remaining: 0m 3s\nProcessed 81/88 test images. Estimated time remaining: 0m 3s\nProcessed 82/88 test images. Estimated time remaining: 0m 2s\nProcessed 83/88 test images. Estimated time remaining: 0m 2s\nProcessed 84/88 test images. Estimated time remaining: 0m 2s\nProcessed 85/88 test images. Estimated time remaining: 0m 1s\nProcessed 86/88 test images. Estimated time remaining: 0m 1s\nProcessed 87/88 test images. Estimated time remaining: 0m 0s\nProcessed 88/88 test images. Estimated time remaining: 0m 0s\nProcessed 88 test images in 0m 33s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.read_csv('test_matched_units.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:51:00.294676Z",
          "iopub.execute_input": "2024-09-16T06:51:00.295082Z",
          "iopub.status.idle": "2024-09-16T06:51:00.302593Z",
          "shell.execute_reply.started": "2024-09-16T06:51:00.295045Z",
          "shell.execute_reply": "2024-09-16T06:51:00.301757Z"
        },
        "trusted": true,
        "id": "9i0-P3bWmz1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head(30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:51:01.527298Z",
          "iopub.execute_input": "2024-09-16T06:51:01.527687Z",
          "iopub.status.idle": "2024-09-16T06:51:01.546431Z",
          "shell.execute_reply.started": "2024-09-16T06:51:01.52765Z",
          "shell.execute_reply": "2024-09-16T06:51:01.545602Z"
        },
        "trusted": true,
        "id": "qHsRr7fgmz1_",
        "outputId": "c665fb3d-5620-4d67-9f52-7b3017408e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                           image_link  \\\n0   https://m.media-amazon.com/images/I/41-NCxNuBx...   \n1   https://m.media-amazon.com/images/I/41-NCxNuBx...   \n2   https://m.media-amazon.com/images/I/41ADVPQgZO...   \n3   https://m.media-amazon.com/images/I/417NJrPEk+...   \n4   https://m.media-amazon.com/images/I/41nblnEkJ3...   \n5   https://m.media-amazon.com/images/I/41pvwR9Gba...   \n6   https://m.media-amazon.com/images/I/41nblnEkJ3...   \n7   https://m.media-amazon.com/images/I/41uwo4PVnu...   \n8   https://m.media-amazon.com/images/I/41ygXRvf8l...   \n9   https://m.media-amazon.com/images/I/41uwo4PVnu...   \n10  https://m.media-amazon.com/images/I/41ygXRvf8l...   \n11  https://m.media-amazon.com/images/I/41zgjN+zW3...   \n12  https://m.media-amazon.com/images/I/41o3iis9E7...   \n13  https://m.media-amazon.com/images/I/51+oHGvSvu...   \n14  https://m.media-amazon.com/images/I/417SThj+Sr...   \n15  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n16  https://m.media-amazon.com/images/I/51+oHGvSvu...   \n17  https://m.media-amazon.com/images/I/417SThj+Sr...   \n18  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n19  https://m.media-amazon.com/images/I/51-WIOx5px...   \n20  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n21  https://m.media-amazon.com/images/I/51-WIOx5px...   \n22  https://m.media-amazon.com/images/I/514bY8c4ZI...   \n23  https://m.media-amazon.com/images/I/51EBBqNOJ1...   \n24  https://m.media-amazon.com/images/I/514bY8c4ZI...   \n25  https://m.media-amazon.com/images/I/51EBBqNOJ1...   \n26  https://m.media-amazon.com/images/I/51BEuVR4Zz...   \n27  https://m.media-amazon.com/images/I/514pScQdlC...   \n28  https://m.media-amazon.com/images/I/51BEuVR4Zz...   \n29  https://m.media-amazon.com/images/I/514pScQdlC...   \n\n                      entity_name  group_id  \\\n0                           width    658003   \n1                           depth    658003   \n2                     item_weight    993359   \n3   maximum_weight_recommendation    939426   \n4                         voltage    648011   \n5                         voltage    965518   \n6                         wattage    648011   \n7                           depth    640565   \n8                          height    752266   \n9                           width    640565   \n10                          depth    752266   \n11                    item_weight    359286   \n12                         height    487566   \n13                          depth    442321   \n14                        voltage    276700   \n15                          depth    683885   \n16                          width    442321   \n17                        wattage    276700   \n18                         height    683885   \n19                          depth    178778   \n20                          depth    683885   \n21                         height    178778   \n22                          width    752266   \n23                          width    483370   \n24                          depth    752266   \n25                          depth    483370   \n26                          width    695925   \n27                        voltage    997176   \n28                         height    695925   \n29                        wattage    997176   \n\n                                       extracted_text  \\\n0                                           2OCM 1SCM   \n1                                           2OCM 1SCM   \n2                              CalaLrian Chili Powder   \n3   Deodorizing module Cat litter shovel Adsorb ba...   \n4             LED OSRAM 55w= 40w 470 Im am White B22d   \n5             LED WORK LIGHT for Dark Areas 'DAKLAR |   \n6             LED OSRAM 55w= 40w 470 Im am White B22d   \n7                                              Joz\" [   \n8                                            50cm 8cm   \n9                                              Joz\" [   \n10                                           50cm 8cm   \n11                                       44\" 6.75 LBS   \n12  Ideal Bed & Armchair Cover Neat size foldaway ...   \n13                         Desktop Size 40\" 24\" { 1 o   \n14  Professional tools Blade Diameter Sosti Rated ...   \n15                         Width 1C.M: Length 9 Meter   \n16                         Desktop Size 40\" 24\" { 1 o   \n17  Professional tools Blade Diameter Sosti Rated ...   \n18                         Width 1C.M: Length 9 Meter   \n19            d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm   \n20                         Width 1C.M: Length 9 Meter   \n21            d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm   \n22                                         3 3  F N {   \n23                                            7.8inch   \n24                                         3 3  F N {   \n25                                            7.8inch   \n26                                  70 XRt 110_ cm cm   \n27  12V Car Heating  Powered by DC 12V cigarette l...   \n28                                  70 XRt 110_ cm cm   \n29  12V Car Heating  Powered by DC 12V cigarette l...   \n\n                                      predicted_units  \\\n0                   ['1 centimetre', '20 centimetre']   \n1                   ['1 centimetre', '20 centimetre']   \n2                                                  []   \n3                                                  []   \n4                                                  []   \n5                                                  []   \n6                              ['55 watt', '40 watt']   \n7                                                  []   \n8                   ['50 centimetre', '8 centimetre']   \n9                                                  []   \n10                  ['50 centimetre', '8 centimetre']   \n11                                     ['6.75 pound']   \n12                                   ['0 centimetre']   \n13                             ['24 inch', '40 inch']   \n14                                                 []   \n15                                        ['9 metre']   \n16                             ['24 inch', '40 inch']   \n17                                      ['2100 watt']   \n18                                        ['9 metre']   \n19  ['24 centimetre', '16 centimetre', '6.2 inch',...   \n20                                        ['9 metre']   \n21  ['24 centimetre', '16 centimetre', '6.2 inch',...   \n22                                                 []   \n23                                       ['7.8 inch']   \n24                                                 []   \n25                                       ['7.8 inch']   \n26                                                 []   \n27                              ['0 volt', '12 volt']   \n28                                                 []   \n29                                         ['0 watt']   \n\n                                           predicted  \n0                        1 centimetre, 20 centimetre  \n1                        1 centimetre, 20 centimetre  \n2                                                NaN  \n3                                                NaN  \n4                                                NaN  \n5                                                NaN  \n6                                   55 watt, 40 watt  \n7                                                NaN  \n8                        50 centimetre, 8 centimetre  \n9                                                NaN  \n10                       50 centimetre, 8 centimetre  \n11                                        6.75 pound  \n12                                      0 centimetre  \n13                                  24 inch, 40 inch  \n14                                               NaN  \n15                                           9 metre  \n16                                  24 inch, 40 inch  \n17                                         2100 watt  \n18                                           9 metre  \n19  24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch  \n20                                           9 metre  \n21  24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch  \n22                                               NaN  \n23                                          7.8 inch  \n24                                               NaN  \n25                                          7.8 inch  \n26                                               NaN  \n27                                   0 volt, 12 volt  \n28                                               NaN  \n29                                            0 watt  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_link</th>\n      <th>entity_name</th>\n      <th>group_id</th>\n      <th>extracted_text</th>\n      <th>predicted_units</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://m.media-amazon.com/images/I/41-NCxNuBx...</td>\n      <td>width</td>\n      <td>658003</td>\n      <td>2OCM 1SCM</td>\n      <td>['1 centimetre', '20 centimetre']</td>\n      <td>1 centimetre, 20 centimetre</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://m.media-amazon.com/images/I/41-NCxNuBx...</td>\n      <td>depth</td>\n      <td>658003</td>\n      <td>2OCM 1SCM</td>\n      <td>['1 centimetre', '20 centimetre']</td>\n      <td>1 centimetre, 20 centimetre</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://m.media-amazon.com/images/I/41ADVPQgZO...</td>\n      <td>item_weight</td>\n      <td>993359</td>\n      <td>CalaLrian Chili Powder</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://m.media-amazon.com/images/I/417NJrPEk+...</td>\n      <td>maximum_weight_recommendation</td>\n      <td>939426</td>\n      <td>Deodorizing module Cat litter shovel Adsorb ba...</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://m.media-amazon.com/images/I/41nblnEkJ3...</td>\n      <td>voltage</td>\n      <td>648011</td>\n      <td>LED OSRAM 55w= 40w 470 Im am White B22d</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://m.media-amazon.com/images/I/41pvwR9Gba...</td>\n      <td>voltage</td>\n      <td>965518</td>\n      <td>LED WORK LIGHT for Dark Areas 'DAKLAR |</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://m.media-amazon.com/images/I/41nblnEkJ3...</td>\n      <td>wattage</td>\n      <td>648011</td>\n      <td>LED OSRAM 55w= 40w 470 Im am White B22d</td>\n      <td>['55 watt', '40 watt']</td>\n      <td>55 watt, 40 watt</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>https://m.media-amazon.com/images/I/41uwo4PVnu...</td>\n      <td>depth</td>\n      <td>640565</td>\n      <td>Joz\" [</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>https://m.media-amazon.com/images/I/41ygXRvf8l...</td>\n      <td>height</td>\n      <td>752266</td>\n      <td>50cm 8cm</td>\n      <td>['50 centimetre', '8 centimetre']</td>\n      <td>50 centimetre, 8 centimetre</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>https://m.media-amazon.com/images/I/41uwo4PVnu...</td>\n      <td>width</td>\n      <td>640565</td>\n      <td>Joz\" [</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>https://m.media-amazon.com/images/I/41ygXRvf8l...</td>\n      <td>depth</td>\n      <td>752266</td>\n      <td>50cm 8cm</td>\n      <td>['50 centimetre', '8 centimetre']</td>\n      <td>50 centimetre, 8 centimetre</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>https://m.media-amazon.com/images/I/41zgjN+zW3...</td>\n      <td>item_weight</td>\n      <td>359286</td>\n      <td>44\" 6.75 LBS</td>\n      <td>['6.75 pound']</td>\n      <td>6.75 pound</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>https://m.media-amazon.com/images/I/41o3iis9E7...</td>\n      <td>height</td>\n      <td>487566</td>\n      <td>Ideal Bed &amp; Armchair Cover Neat size foldaway ...</td>\n      <td>['0 centimetre']</td>\n      <td>0 centimetre</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>https://m.media-amazon.com/images/I/51+oHGvSvu...</td>\n      <td>depth</td>\n      <td>442321</td>\n      <td>Desktop Size 40\" 24\" { 1 o</td>\n      <td>['24 inch', '40 inch']</td>\n      <td>24 inch, 40 inch</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>https://m.media-amazon.com/images/I/417SThj+Sr...</td>\n      <td>voltage</td>\n      <td>276700</td>\n      <td>Professional tools Blade Diameter Sosti Rated ...</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>https://m.media-amazon.com/images/I/510xYFNYQ8...</td>\n      <td>depth</td>\n      <td>683885</td>\n      <td>Width 1C.M: Length 9 Meter</td>\n      <td>['9 metre']</td>\n      <td>9 metre</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>https://m.media-amazon.com/images/I/51+oHGvSvu...</td>\n      <td>width</td>\n      <td>442321</td>\n      <td>Desktop Size 40\" 24\" { 1 o</td>\n      <td>['24 inch', '40 inch']</td>\n      <td>24 inch, 40 inch</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>https://m.media-amazon.com/images/I/417SThj+Sr...</td>\n      <td>wattage</td>\n      <td>276700</td>\n      <td>Professional tools Blade Diameter Sosti Rated ...</td>\n      <td>['2100 watt']</td>\n      <td>2100 watt</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>https://m.media-amazon.com/images/I/510xYFNYQ8...</td>\n      <td>height</td>\n      <td>683885</td>\n      <td>Width 1C.M: Length 9 Meter</td>\n      <td>['9 metre']</td>\n      <td>9 metre</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>https://m.media-amazon.com/images/I/51-WIOx5px...</td>\n      <td>depth</td>\n      <td>178778</td>\n      <td>d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm</td>\n      <td>['24 centimetre', '16 centimetre', '6.2 inch',...</td>\n      <td>24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>https://m.media-amazon.com/images/I/510xYFNYQ8...</td>\n      <td>depth</td>\n      <td>683885</td>\n      <td>Width 1C.M: Length 9 Meter</td>\n      <td>['9 metre']</td>\n      <td>9 metre</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>https://m.media-amazon.com/images/I/51-WIOx5px...</td>\n      <td>height</td>\n      <td>178778</td>\n      <td>d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm</td>\n      <td>['24 centimetre', '16 centimetre', '6.2 inch',...</td>\n      <td>24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>https://m.media-amazon.com/images/I/514bY8c4ZI...</td>\n      <td>width</td>\n      <td>752266</td>\n      <td>3 3  F N {</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>https://m.media-amazon.com/images/I/51EBBqNOJ1...</td>\n      <td>width</td>\n      <td>483370</td>\n      <td>7.8inch</td>\n      <td>['7.8 inch']</td>\n      <td>7.8 inch</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>https://m.media-amazon.com/images/I/514bY8c4ZI...</td>\n      <td>depth</td>\n      <td>752266</td>\n      <td>3 3  F N {</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>https://m.media-amazon.com/images/I/51EBBqNOJ1...</td>\n      <td>depth</td>\n      <td>483370</td>\n      <td>7.8inch</td>\n      <td>['7.8 inch']</td>\n      <td>7.8 inch</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>https://m.media-amazon.com/images/I/51BEuVR4Zz...</td>\n      <td>width</td>\n      <td>695925</td>\n      <td>70 XRt 110_ cm cm</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>https://m.media-amazon.com/images/I/514pScQdlC...</td>\n      <td>voltage</td>\n      <td>997176</td>\n      <td>12V Car Heating  Powered by DC 12V cigarette l...</td>\n      <td>['0 volt', '12 volt']</td>\n      <td>0 volt, 12 volt</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>https://m.media-amazon.com/images/I/51BEuVR4Zz...</td>\n      <td>height</td>\n      <td>695925</td>\n      <td>70 XRt 110_ cm cm</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>https://m.media-amazon.com/images/I/514pScQdlC...</td>\n      <td>wattage</td>\n      <td>997176</td>\n      <td>12V Car Heating  Powered by DC 12V cigarette l...</td>\n      <td>['0 watt']</td>\n      <td>0 watt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'predicted' column from a list of strings to a single string without brackets and quotes\n",
        "final_df['predicted_units'] = final_df['predicted_units'].apply(lambda x: ', '.join(sorted(set(x.strip('[]').replace(\"'\", \"\").split(', ')))))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:51:03.111805Z",
          "iopub.execute_input": "2024-09-16T06:51:03.112579Z",
          "iopub.status.idle": "2024-09-16T06:51:03.11855Z",
          "shell.execute_reply.started": "2024-09-16T06:51:03.112538Z",
          "shell.execute_reply": "2024-09-16T06:51:03.117635Z"
        },
        "trusted": true,
        "id": "nX3mYkohmz1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = final_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:51:04.560779Z",
          "iopub.execute_input": "2024-09-16T06:51:04.561155Z",
          "iopub.status.idle": "2024-09-16T06:51:04.565565Z",
          "shell.execute_reply.started": "2024-09-16T06:51:04.56112Z",
          "shell.execute_reply": "2024-09-16T06:51:04.564536Z"
        },
        "trusted": true,
        "id": "qOOAeAaMmz2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:51:05.966679Z",
          "iopub.execute_input": "2024-09-16T06:51:05.96756Z",
          "iopub.status.idle": "2024-09-16T06:51:05.979968Z",
          "shell.execute_reply.started": "2024-09-16T06:51:05.967517Z",
          "shell.execute_reply": "2024-09-16T06:51:05.979004Z"
        },
        "trusted": true,
        "id": "p8Cnsaqjmz2A",
        "outputId": "361dd4de-1b78-48f7-cff3-1d0579774d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                          image_link  \\\n0  https://m.media-amazon.com/images/I/41-NCxNuBx...   \n1  https://m.media-amazon.com/images/I/41-NCxNuBx...   \n2  https://m.media-amazon.com/images/I/41ADVPQgZO...   \n3  https://m.media-amazon.com/images/I/417NJrPEk+...   \n4  https://m.media-amazon.com/images/I/41nblnEkJ3...   \n5  https://m.media-amazon.com/images/I/41pvwR9Gba...   \n6  https://m.media-amazon.com/images/I/41nblnEkJ3...   \n7  https://m.media-amazon.com/images/I/41uwo4PVnu...   \n8  https://m.media-amazon.com/images/I/41ygXRvf8l...   \n9  https://m.media-amazon.com/images/I/41uwo4PVnu...   \n\n                     entity_name  group_id  \\\n0                          width    658003   \n1                          depth    658003   \n2                    item_weight    993359   \n3  maximum_weight_recommendation    939426   \n4                        voltage    648011   \n5                        voltage    965518   \n6                        wattage    648011   \n7                          depth    640565   \n8                         height    752266   \n9                          width    640565   \n\n                                      extracted_text  \\\n0                                          2OCM 1SCM   \n1                                          2OCM 1SCM   \n2                             CalaLrian Chili Powder   \n3  Deodorizing module Cat litter shovel Adsorb ba...   \n4            LED OSRAM 55w= 40w 470 Im am White B22d   \n5            LED WORK LIGHT for Dark Areas 'DAKLAR |   \n6            LED OSRAM 55w= 40w 470 Im am White B22d   \n7                                             Joz\" [   \n8                                           50cm 8cm   \n9                                             Joz\" [   \n\n               predicted_units                    predicted  \n0  1 centimetre, 20 centimetre  1 centimetre, 20 centimetre  \n1  1 centimetre, 20 centimetre  1 centimetre, 20 centimetre  \n2                                                       NaN  \n3                                                       NaN  \n4                                                       NaN  \n5                                                       NaN  \n6             40 watt, 55 watt             55 watt, 40 watt  \n7                                                       NaN  \n8  50 centimetre, 8 centimetre  50 centimetre, 8 centimetre  \n9                                                       NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_link</th>\n      <th>entity_name</th>\n      <th>group_id</th>\n      <th>extracted_text</th>\n      <th>predicted_units</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://m.media-amazon.com/images/I/41-NCxNuBx...</td>\n      <td>width</td>\n      <td>658003</td>\n      <td>2OCM 1SCM</td>\n      <td>1 centimetre, 20 centimetre</td>\n      <td>1 centimetre, 20 centimetre</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://m.media-amazon.com/images/I/41-NCxNuBx...</td>\n      <td>depth</td>\n      <td>658003</td>\n      <td>2OCM 1SCM</td>\n      <td>1 centimetre, 20 centimetre</td>\n      <td>1 centimetre, 20 centimetre</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://m.media-amazon.com/images/I/41ADVPQgZO...</td>\n      <td>item_weight</td>\n      <td>993359</td>\n      <td>CalaLrian Chili Powder</td>\n      <td></td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://m.media-amazon.com/images/I/417NJrPEk+...</td>\n      <td>maximum_weight_recommendation</td>\n      <td>939426</td>\n      <td>Deodorizing module Cat litter shovel Adsorb ba...</td>\n      <td></td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://m.media-amazon.com/images/I/41nblnEkJ3...</td>\n      <td>voltage</td>\n      <td>648011</td>\n      <td>LED OSRAM 55w= 40w 470 Im am White B22d</td>\n      <td></td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://m.media-amazon.com/images/I/41pvwR9Gba...</td>\n      <td>voltage</td>\n      <td>965518</td>\n      <td>LED WORK LIGHT for Dark Areas 'DAKLAR |</td>\n      <td></td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://m.media-amazon.com/images/I/41nblnEkJ3...</td>\n      <td>wattage</td>\n      <td>648011</td>\n      <td>LED OSRAM 55w= 40w 470 Im am White B22d</td>\n      <td>40 watt, 55 watt</td>\n      <td>55 watt, 40 watt</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>https://m.media-amazon.com/images/I/41uwo4PVnu...</td>\n      <td>depth</td>\n      <td>640565</td>\n      <td>Joz\" [</td>\n      <td></td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>https://m.media-amazon.com/images/I/41ygXRvf8l...</td>\n      <td>height</td>\n      <td>752266</td>\n      <td>50cm 8cm</td>\n      <td>50 centimetre, 8 centimetre</td>\n      <td>50 centimetre, 8 centimetre</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>https://m.media-amazon.com/images/I/41uwo4PVnu...</td>\n      <td>width</td>\n      <td>640565</td>\n      <td>Joz\" [</td>\n      <td></td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_number(value):\n",
        "    \"\"\"Extract the number from a value string.\"\"\"\n",
        "    match = re.search(r'(\\d+\\.?\\d*)', value)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    return None\n",
        "\n",
        "def convert_to_base_unit(value, unit):\n",
        "    \"\"\"Convert the value to a base unit (e.g., centimeters).\"\"\"\n",
        "    conversions = {\n",
        "        'cm': 1,\n",
        "        'centimetre': 1,\n",
        "        'inch': 2.54,\n",
        "        'foot': 30.48,\n",
        "        'yard': 91.44,\n",
        "        'watt': 1, # Assuming 'watt' does not need conversion\n",
        "        'gram': 1,\n",
        "        'kilogram': 1000,\n",
        "        'ounce': 28.3495,\n",
        "        'pound': 453.592\n",
        "    }\n",
        "    return value * conversions.get(unit, 1)\n",
        "\n",
        "def find_max_value(predicted_units):\n",
        "    \"\"\"Find the maximum value in the predicted_units column.\"\"\"\n",
        "    max_value = -float('inf')\n",
        "    max_unit = None\n",
        "\n",
        "    if not predicted_units:\n",
        "        return None\n",
        "\n",
        "    parts = predicted_units.split(',')\n",
        "    for part in parts:\n",
        "        number_match = re.search(r'(\\d+\\.?\\d*)', part)\n",
        "        unit_match = re.search(r'(cm|centimetre|inch|foot|yard|watt|gram|kilogram|ounce|pound|meter|metre|volt)', part, re.IGNORECASE)\n",
        "        if number_match and unit_match:\n",
        "            number = float(number_match.group(1))\n",
        "            unit = unit_match.group(1).lower()\n",
        "            value_in_base = convert_to_base_unit(number, unit)\n",
        "            if value_in_base > max_value:\n",
        "                max_value = value_in_base\n",
        "                max_unit = part\n",
        "    return max_unit if max_unit else None\n",
        "\n",
        "# Apply the function\n",
        "df['max_predicted_units'] = df['predicted_units'].apply(lambda x: find_max_value(x))\n",
        "\n",
        "print(df[['image_link', 'entity_name', 'predicted_units', 'max_predicted_units']].head(30))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:51:06.868475Z",
          "iopub.execute_input": "2024-09-16T06:51:06.868863Z",
          "iopub.status.idle": "2024-09-16T06:51:06.894197Z",
          "shell.execute_reply.started": "2024-09-16T06:51:06.868826Z",
          "shell.execute_reply": "2024-09-16T06:51:06.893089Z"
        },
        "trusted": true,
        "id": "zy_dybsCmz2A",
        "outputId": "545249ec-cc40-464d-9a44-fec0f84798f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "                                           image_link  \\\n0   https://m.media-amazon.com/images/I/41-NCxNuBx...   \n1   https://m.media-amazon.com/images/I/41-NCxNuBx...   \n2   https://m.media-amazon.com/images/I/41ADVPQgZO...   \n3   https://m.media-amazon.com/images/I/417NJrPEk+...   \n4   https://m.media-amazon.com/images/I/41nblnEkJ3...   \n5   https://m.media-amazon.com/images/I/41pvwR9Gba...   \n6   https://m.media-amazon.com/images/I/41nblnEkJ3...   \n7   https://m.media-amazon.com/images/I/41uwo4PVnu...   \n8   https://m.media-amazon.com/images/I/41ygXRvf8l...   \n9   https://m.media-amazon.com/images/I/41uwo4PVnu...   \n10  https://m.media-amazon.com/images/I/41ygXRvf8l...   \n11  https://m.media-amazon.com/images/I/41zgjN+zW3...   \n12  https://m.media-amazon.com/images/I/41o3iis9E7...   \n13  https://m.media-amazon.com/images/I/51+oHGvSvu...   \n14  https://m.media-amazon.com/images/I/417SThj+Sr...   \n15  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n16  https://m.media-amazon.com/images/I/51+oHGvSvu...   \n17  https://m.media-amazon.com/images/I/417SThj+Sr...   \n18  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n19  https://m.media-amazon.com/images/I/51-WIOx5px...   \n20  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n21  https://m.media-amazon.com/images/I/51-WIOx5px...   \n22  https://m.media-amazon.com/images/I/514bY8c4ZI...   \n23  https://m.media-amazon.com/images/I/51EBBqNOJ1...   \n24  https://m.media-amazon.com/images/I/514bY8c4ZI...   \n25  https://m.media-amazon.com/images/I/51EBBqNOJ1...   \n26  https://m.media-amazon.com/images/I/51BEuVR4Zz...   \n27  https://m.media-amazon.com/images/I/514pScQdlC...   \n28  https://m.media-amazon.com/images/I/51BEuVR4Zz...   \n29  https://m.media-amazon.com/images/I/514pScQdlC...   \n\n                      entity_name  \\\n0                           width   \n1                           depth   \n2                     item_weight   \n3   maximum_weight_recommendation   \n4                         voltage   \n5                         voltage   \n6                         wattage   \n7                           depth   \n8                          height   \n9                           width   \n10                          depth   \n11                    item_weight   \n12                         height   \n13                          depth   \n14                        voltage   \n15                          depth   \n16                          width   \n17                        wattage   \n18                         height   \n19                          depth   \n20                          depth   \n21                         height   \n22                          width   \n23                          width   \n24                          depth   \n25                          depth   \n26                          width   \n27                        voltage   \n28                         height   \n29                        wattage   \n\n                                     predicted_units max_predicted_units  \n0                        1 centimetre, 20 centimetre       20 centimetre  \n1                        1 centimetre, 20 centimetre       20 centimetre  \n2                                                                   None  \n3                                                                   None  \n4                                                                   None  \n5                                                                   None  \n6                                   40 watt, 55 watt             55 watt  \n7                                                                   None  \n8                        50 centimetre, 8 centimetre       50 centimetre  \n9                                                                   None  \n10                       50 centimetre, 8 centimetre       50 centimetre  \n11                                        6.75 pound          6.75 pound  \n12                                      0 centimetre        0 centimetre  \n13                                  24 inch, 40 inch             40 inch  \n14                                                                  None  \n15                                           9 metre             9 metre  \n16                                  24 inch, 40 inch             40 inch  \n17                                         2100 watt           2100 watt  \n18                                           9 metre             9 metre  \n19  16 centimetre, 24 centimetre, 6.2 inch, 9.4 inch       24 centimetre  \n20                                           9 metre             9 metre  \n21  16 centimetre, 24 centimetre, 6.2 inch, 9.4 inch       24 centimetre  \n22                                                                  None  \n23                                          7.8 inch            7.8 inch  \n24                                                                  None  \n25                                          7.8 inch            7.8 inch  \n26                                                                  None  \n27                                   0 volt, 12 volt             12 volt  \n28                                                                  None  \n29                                            0 watt              0 watt  \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:51:08.05122Z",
          "iopub.execute_input": "2024-09-16T06:51:08.05194Z",
          "iopub.status.idle": "2024-09-16T06:51:08.071329Z",
          "shell.execute_reply.started": "2024-09-16T06:51:08.051899Z",
          "shell.execute_reply": "2024-09-16T06:51:08.070219Z"
        },
        "trusted": true,
        "id": "pEwBEXrrmz2A",
        "outputId": "d4130093-b1b2-4a04-f62e-9c1151bbdb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                           image_link  \\\n0   https://m.media-amazon.com/images/I/41-NCxNuBx...   \n1   https://m.media-amazon.com/images/I/41-NCxNuBx...   \n2   https://m.media-amazon.com/images/I/41ADVPQgZO...   \n3   https://m.media-amazon.com/images/I/417NJrPEk+...   \n4   https://m.media-amazon.com/images/I/41nblnEkJ3...   \n5   https://m.media-amazon.com/images/I/41pvwR9Gba...   \n6   https://m.media-amazon.com/images/I/41nblnEkJ3...   \n7   https://m.media-amazon.com/images/I/41uwo4PVnu...   \n8   https://m.media-amazon.com/images/I/41ygXRvf8l...   \n9   https://m.media-amazon.com/images/I/41uwo4PVnu...   \n10  https://m.media-amazon.com/images/I/41ygXRvf8l...   \n11  https://m.media-amazon.com/images/I/41zgjN+zW3...   \n12  https://m.media-amazon.com/images/I/41o3iis9E7...   \n13  https://m.media-amazon.com/images/I/51+oHGvSvu...   \n14  https://m.media-amazon.com/images/I/417SThj+Sr...   \n15  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n16  https://m.media-amazon.com/images/I/51+oHGvSvu...   \n17  https://m.media-amazon.com/images/I/417SThj+Sr...   \n18  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n19  https://m.media-amazon.com/images/I/51-WIOx5px...   \n20  https://m.media-amazon.com/images/I/510xYFNYQ8...   \n21  https://m.media-amazon.com/images/I/51-WIOx5px...   \n22  https://m.media-amazon.com/images/I/514bY8c4ZI...   \n23  https://m.media-amazon.com/images/I/51EBBqNOJ1...   \n24  https://m.media-amazon.com/images/I/514bY8c4ZI...   \n25  https://m.media-amazon.com/images/I/51EBBqNOJ1...   \n26  https://m.media-amazon.com/images/I/51BEuVR4Zz...   \n27  https://m.media-amazon.com/images/I/514pScQdlC...   \n28  https://m.media-amazon.com/images/I/51BEuVR4Zz...   \n29  https://m.media-amazon.com/images/I/514pScQdlC...   \n\n                      entity_name  group_id  \\\n0                           width    658003   \n1                           depth    658003   \n2                     item_weight    993359   \n3   maximum_weight_recommendation    939426   \n4                         voltage    648011   \n5                         voltage    965518   \n6                         wattage    648011   \n7                           depth    640565   \n8                          height    752266   \n9                           width    640565   \n10                          depth    752266   \n11                    item_weight    359286   \n12                         height    487566   \n13                          depth    442321   \n14                        voltage    276700   \n15                          depth    683885   \n16                          width    442321   \n17                        wattage    276700   \n18                         height    683885   \n19                          depth    178778   \n20                          depth    683885   \n21                         height    178778   \n22                          width    752266   \n23                          width    483370   \n24                          depth    752266   \n25                          depth    483370   \n26                          width    695925   \n27                        voltage    997176   \n28                         height    695925   \n29                        wattage    997176   \n\n                                       extracted_text  \\\n0                                           2OCM 1SCM   \n1                                           2OCM 1SCM   \n2                              CalaLrian Chili Powder   \n3   Deodorizing module Cat litter shovel Adsorb ba...   \n4             LED OSRAM 55w= 40w 470 Im am White B22d   \n5             LED WORK LIGHT for Dark Areas 'DAKLAR |   \n6             LED OSRAM 55w= 40w 470 Im am White B22d   \n7                                              Joz\" [   \n8                                            50cm 8cm   \n9                                              Joz\" [   \n10                                           50cm 8cm   \n11                                       44\" 6.75 LBS   \n12  Ideal Bed & Armchair Cover Neat size foldaway ...   \n13                         Desktop Size 40\" 24\" { 1 o   \n14  Professional tools Blade Diameter Sosti Rated ...   \n15                         Width 1C.M: Length 9 Meter   \n16                         Desktop Size 40\" 24\" { 1 o   \n17  Professional tools Blade Diameter Sosti Rated ...   \n18                         Width 1C.M: Length 9 Meter   \n19            d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm   \n20                         Width 1C.M: Length 9 Meter   \n21            d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm   \n22                                         3 3  F N {   \n23                                            7.8inch   \n24                                         3 3  F N {   \n25                                            7.8inch   \n26                                  70 XRt 110_ cm cm   \n27  12V Car Heating  Powered by DC 12V cigarette l...   \n28                                  70 XRt 110_ cm cm   \n29  12V Car Heating  Powered by DC 12V cigarette l...   \n\n                                     predicted_units  \\\n0                        1 centimetre, 20 centimetre   \n1                        1 centimetre, 20 centimetre   \n2                                                      \n3                                                      \n4                                                      \n5                                                      \n6                                   40 watt, 55 watt   \n7                                                      \n8                        50 centimetre, 8 centimetre   \n9                                                      \n10                       50 centimetre, 8 centimetre   \n11                                        6.75 pound   \n12                                      0 centimetre   \n13                                  24 inch, 40 inch   \n14                                                     \n15                                           9 metre   \n16                                  24 inch, 40 inch   \n17                                         2100 watt   \n18                                           9 metre   \n19  16 centimetre, 24 centimetre, 6.2 inch, 9.4 inch   \n20                                           9 metre   \n21  16 centimetre, 24 centimetre, 6.2 inch, 9.4 inch   \n22                                                     \n23                                          7.8 inch   \n24                                                     \n25                                          7.8 inch   \n26                                                     \n27                                   0 volt, 12 volt   \n28                                                     \n29                                            0 watt   \n\n                                           predicted max_predicted_units  \n0                        1 centimetre, 20 centimetre       20 centimetre  \n1                        1 centimetre, 20 centimetre       20 centimetre  \n2                                                NaN                None  \n3                                                NaN                None  \n4                                                NaN                None  \n5                                                NaN                None  \n6                                   55 watt, 40 watt             55 watt  \n7                                                NaN                None  \n8                        50 centimetre, 8 centimetre       50 centimetre  \n9                                                NaN                None  \n10                       50 centimetre, 8 centimetre       50 centimetre  \n11                                        6.75 pound          6.75 pound  \n12                                      0 centimetre        0 centimetre  \n13                                  24 inch, 40 inch             40 inch  \n14                                               NaN                None  \n15                                           9 metre             9 metre  \n16                                  24 inch, 40 inch             40 inch  \n17                                         2100 watt           2100 watt  \n18                                           9 metre             9 metre  \n19  24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch       24 centimetre  \n20                                           9 metre             9 metre  \n21  24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch       24 centimetre  \n22                                               NaN                None  \n23                                          7.8 inch            7.8 inch  \n24                                               NaN                None  \n25                                          7.8 inch            7.8 inch  \n26                                               NaN                None  \n27                                   0 volt, 12 volt             12 volt  \n28                                               NaN                None  \n29                                            0 watt              0 watt  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_link</th>\n      <th>entity_name</th>\n      <th>group_id</th>\n      <th>extracted_text</th>\n      <th>predicted_units</th>\n      <th>predicted</th>\n      <th>max_predicted_units</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://m.media-amazon.com/images/I/41-NCxNuBx...</td>\n      <td>width</td>\n      <td>658003</td>\n      <td>2OCM 1SCM</td>\n      <td>1 centimetre, 20 centimetre</td>\n      <td>1 centimetre, 20 centimetre</td>\n      <td>20 centimetre</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://m.media-amazon.com/images/I/41-NCxNuBx...</td>\n      <td>depth</td>\n      <td>658003</td>\n      <td>2OCM 1SCM</td>\n      <td>1 centimetre, 20 centimetre</td>\n      <td>1 centimetre, 20 centimetre</td>\n      <td>20 centimetre</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://m.media-amazon.com/images/I/41ADVPQgZO...</td>\n      <td>item_weight</td>\n      <td>993359</td>\n      <td>CalaLrian Chili Powder</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://m.media-amazon.com/images/I/417NJrPEk+...</td>\n      <td>maximum_weight_recommendation</td>\n      <td>939426</td>\n      <td>Deodorizing module Cat litter shovel Adsorb ba...</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://m.media-amazon.com/images/I/41nblnEkJ3...</td>\n      <td>voltage</td>\n      <td>648011</td>\n      <td>LED OSRAM 55w= 40w 470 Im am White B22d</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://m.media-amazon.com/images/I/41pvwR9Gba...</td>\n      <td>voltage</td>\n      <td>965518</td>\n      <td>LED WORK LIGHT for Dark Areas 'DAKLAR |</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://m.media-amazon.com/images/I/41nblnEkJ3...</td>\n      <td>wattage</td>\n      <td>648011</td>\n      <td>LED OSRAM 55w= 40w 470 Im am White B22d</td>\n      <td>40 watt, 55 watt</td>\n      <td>55 watt, 40 watt</td>\n      <td>55 watt</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>https://m.media-amazon.com/images/I/41uwo4PVnu...</td>\n      <td>depth</td>\n      <td>640565</td>\n      <td>Joz\" [</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>https://m.media-amazon.com/images/I/41ygXRvf8l...</td>\n      <td>height</td>\n      <td>752266</td>\n      <td>50cm 8cm</td>\n      <td>50 centimetre, 8 centimetre</td>\n      <td>50 centimetre, 8 centimetre</td>\n      <td>50 centimetre</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>https://m.media-amazon.com/images/I/41uwo4PVnu...</td>\n      <td>width</td>\n      <td>640565</td>\n      <td>Joz\" [</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>https://m.media-amazon.com/images/I/41ygXRvf8l...</td>\n      <td>depth</td>\n      <td>752266</td>\n      <td>50cm 8cm</td>\n      <td>50 centimetre, 8 centimetre</td>\n      <td>50 centimetre, 8 centimetre</td>\n      <td>50 centimetre</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>https://m.media-amazon.com/images/I/41zgjN+zW3...</td>\n      <td>item_weight</td>\n      <td>359286</td>\n      <td>44\" 6.75 LBS</td>\n      <td>6.75 pound</td>\n      <td>6.75 pound</td>\n      <td>6.75 pound</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>https://m.media-amazon.com/images/I/41o3iis9E7...</td>\n      <td>height</td>\n      <td>487566</td>\n      <td>Ideal Bed &amp; Armchair Cover Neat size foldaway ...</td>\n      <td>0 centimetre</td>\n      <td>0 centimetre</td>\n      <td>0 centimetre</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>https://m.media-amazon.com/images/I/51+oHGvSvu...</td>\n      <td>depth</td>\n      <td>442321</td>\n      <td>Desktop Size 40\" 24\" { 1 o</td>\n      <td>24 inch, 40 inch</td>\n      <td>24 inch, 40 inch</td>\n      <td>40 inch</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>https://m.media-amazon.com/images/I/417SThj+Sr...</td>\n      <td>voltage</td>\n      <td>276700</td>\n      <td>Professional tools Blade Diameter Sosti Rated ...</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>https://m.media-amazon.com/images/I/510xYFNYQ8...</td>\n      <td>depth</td>\n      <td>683885</td>\n      <td>Width 1C.M: Length 9 Meter</td>\n      <td>9 metre</td>\n      <td>9 metre</td>\n      <td>9 metre</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>https://m.media-amazon.com/images/I/51+oHGvSvu...</td>\n      <td>width</td>\n      <td>442321</td>\n      <td>Desktop Size 40\" 24\" { 1 o</td>\n      <td>24 inch, 40 inch</td>\n      <td>24 inch, 40 inch</td>\n      <td>40 inch</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>https://m.media-amazon.com/images/I/417SThj+Sr...</td>\n      <td>wattage</td>\n      <td>276700</td>\n      <td>Professional tools Blade Diameter Sosti Rated ...</td>\n      <td>2100 watt</td>\n      <td>2100 watt</td>\n      <td>2100 watt</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>https://m.media-amazon.com/images/I/510xYFNYQ8...</td>\n      <td>height</td>\n      <td>683885</td>\n      <td>Width 1C.M: Length 9 Meter</td>\n      <td>9 metre</td>\n      <td>9 metre</td>\n      <td>9 metre</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>https://m.media-amazon.com/images/I/51-WIOx5px...</td>\n      <td>depth</td>\n      <td>178778</td>\n      <td>d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm</td>\n      <td>16 centimetre, 24 centimetre, 6.2 inch, 9.4 inch</td>\n      <td>24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch</td>\n      <td>24 centimetre</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>https://m.media-amazon.com/images/I/510xYFNYQ8...</td>\n      <td>depth</td>\n      <td>683885</td>\n      <td>Width 1C.M: Length 9 Meter</td>\n      <td>9 metre</td>\n      <td>9 metre</td>\n      <td>9 metre</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>https://m.media-amazon.com/images/I/51-WIOx5px...</td>\n      <td>height</td>\n      <td>178778</td>\n      <td>d1, 6.2 in / 16 cm 9.4 in / 24 cm Soudm</td>\n      <td>16 centimetre, 24 centimetre, 6.2 inch, 9.4 inch</td>\n      <td>24 centimetre, 16 centimetre, 6.2 inch, 9.4 inch</td>\n      <td>24 centimetre</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>https://m.media-amazon.com/images/I/514bY8c4ZI...</td>\n      <td>width</td>\n      <td>752266</td>\n      <td>3 3  F N {</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>https://m.media-amazon.com/images/I/51EBBqNOJ1...</td>\n      <td>width</td>\n      <td>483370</td>\n      <td>7.8inch</td>\n      <td>7.8 inch</td>\n      <td>7.8 inch</td>\n      <td>7.8 inch</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>https://m.media-amazon.com/images/I/514bY8c4ZI...</td>\n      <td>depth</td>\n      <td>752266</td>\n      <td>3 3  F N {</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>https://m.media-amazon.com/images/I/51EBBqNOJ1...</td>\n      <td>depth</td>\n      <td>483370</td>\n      <td>7.8inch</td>\n      <td>7.8 inch</td>\n      <td>7.8 inch</td>\n      <td>7.8 inch</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>https://m.media-amazon.com/images/I/51BEuVR4Zz...</td>\n      <td>width</td>\n      <td>695925</td>\n      <td>70 XRt 110_ cm cm</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>https://m.media-amazon.com/images/I/514pScQdlC...</td>\n      <td>voltage</td>\n      <td>997176</td>\n      <td>12V Car Heating  Powered by DC 12V cigarette l...</td>\n      <td>0 volt, 12 volt</td>\n      <td>0 volt, 12 volt</td>\n      <td>12 volt</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>https://m.media-amazon.com/images/I/51BEuVR4Zz...</td>\n      <td>height</td>\n      <td>695925</td>\n      <td>70 XRt 110_ cm cm</td>\n      <td></td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>https://m.media-amazon.com/images/I/514pScQdlC...</td>\n      <td>wattage</td>\n      <td>997176</td>\n      <td>12V Car Heating  Powered by DC 12V cigarette l...</td>\n      <td>0 watt</td>\n      <td>0 watt</td>\n      <td>0 watt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('processed_data.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-16T06:52:19.625108Z",
          "iopub.execute_input": "2024-09-16T06:52:19.625526Z",
          "iopub.status.idle": "2024-09-16T06:52:19.632268Z",
          "shell.execute_reply.started": "2024-09-16T06:52:19.625484Z",
          "shell.execute_reply": "2024-09-16T06:52:19.631337Z"
        },
        "trusted": true,
        "id": "kthSJKWSmz2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}